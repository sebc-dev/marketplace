# Marqueurs lexicaux des LLM : inventaire quantitatif et dynamique de dÃ©tection

**Les textes gÃ©nÃ©rÃ©s par LLM portent une empreinte lexicale statistiquement mesurable**, dÃ©sormais documentÃ©e par au moins cinq Ã©tudes quantitatives majeures Ã  grande Ã©chelle. L'Ã©tude de rÃ©fÃ©rence â€” Kobak et al. (2025) dans _Science Advances_ â€” identifie **379 mots de style surreprÃ©sentÃ©s** dans les abstracts PubMed de 2024, estimant qu'au minimum **13,5 % des publications biomÃ©dicales** de cette annÃ©e ont Ã©tÃ© traitÃ©es par LLM. Ce phÃ©nomÃ¨ne dÃ©passe en ampleur l'impact linguistique de la pandÃ©mie de COVID-19 sur le vocabulaire scientifique. Pour le franÃ§ais, les donnÃ©es quantitatives restent quasi inexistantes : aucune Ã©tude comparable n'a Ã©tÃ© publiÃ©e, bien que des observations convergentes de praticiens francophones documentent un phÃ©nomÃ¨ne analogue, caractÃ©risÃ© par un registre excessivement formel et un Â« accent anglais Â» syntaxique.

---

## Section 1 â€” Inventaire lexical enrichi (anglais)

Les donnÃ©es ci-dessous proviennent de cinq Ã©tudes principales : Kobak, GonzÃ¡lez-MÃ¡rquez, HorvÃ¡t & Lause (2025, _Science Advances_) sur 15,1 millions d'abstracts PubMed ; Gray (2024, arXiv:2403.16887) sur ~5 millions d'articles via Dimensions ; Liang et al. (2025, _Nature Human Behaviour_) sur 1,12 million de preprints ; Matsui (2025, _Perspectives on Medical Education_) sur 26,4 millions d'entrÃ©es PubMed ; et les donnÃ©es du scanner de vocabulaire IA de GPTZero (2024).

### Mots individuels avec donnÃ©es quantitatives prÃ©cises

|Mot/Expression|CatÃ©gorie linguistique|DonnÃ©es quantitatives|Corpus source|Source acadÃ©mique|Preuve|
|---|---|---|---|---|---|
|**underscores**|Verbe d'emphase|Ratio r = **13,8Ã—** (frÃ©quence observÃ©e/attendue 2024)|PubMed 15,1M abstracts|Kobak et al., _Science Advances_ 11(27), 2025|ğŸŸ¢|
|**showcasing**|Verbe promotionnel|Ratio r = **10,7Ã—** ; **20Ã—** surreprÃ©sentation IA|PubMed + arXiv CS|Kobak et al. 2025 ; Liang et al. _Nature Human Behaviour_ 2025 ; GPTZero 2024|ğŸŸ¢|
|**potential**|Hedging / possibilitÃ©|Ã‰cart de frÃ©quence Î´ = **0,052** (plus grand Ã©cart absolu de 2024)|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**findings**|Nominalisation|Î´ = **0,041**|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**crucial**|Intensifier Ã©valuatif|Î´ = **0,037**|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**intricate**|Adjectif Ã©valuatif|**+117 %** entre 2022 et 2023 ; top-4 par log odds ratio|Dimensions ~5M articles + arXiv CS|Gray 2024 ; Liang et al. 2025|ğŸŸ¢|
|**groundbreaking**|Adjectif hyperbolique|**+52 %** entre 2022 et 2023|Dimensions|Gray 2024|ğŸŸ¢|
|**outwith**|PrÃ©position (Ã©cossais)|**+185 %** entre 2022 et 2023|Dimensions|Gray 2024|ğŸŸ¢|
|**innovative**|Adjectif promotionnel|AccÃ©lÃ©ration marquÃ©e en 2023 ; parmi les top adjectifs dans les peer reviews post-ChatGPT|Dimensions + reviews ICLR/NeurIPS|Gray 2024 ; Liang et al. ICML 2024|ğŸŸ¢|
|**versatile**|Adjectif Ã©valuatif|AccÃ©lÃ©ration en 2023, confirmÃ© indÃ©pendamment|Dimensions + reviews IA|Gray 2024 ; Liang et al. ICML 2024|ğŸŸ¢|
|**innovatively**|Adverbe|**~+60 %** entre 2022 et 2023|Dimensions|Gray 2024|ğŸŸ¢|
|**methodically**|Adverbe|**+26 %** entre 2022 et 2023|Dimensions|Gray 2024|ğŸŸ¢|
|**comprehensive**|Adjectif de portÃ©e|Membre du set de 10 mots communs excÃ©dentaires (Î”_common = 0,134)|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**notably**|Marqueur discursif|Membre du set des 10 mots communs excÃ©dentaires|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**enhancing**|Verbe amÃ©lioratif|Membre du set des 10 mots communs excÃ©dentaires|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**additionally**|Connecteur discursif|Membre du set des 10 mots communs excÃ©dentaires|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**exhibited**|Verbe formel|Membre du set des 10 mots communs excÃ©dentaires|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**insights**|Nominalisation|Membre du set des 10 mots communs excÃ©dentaires|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**particularly**|Adverbe intensifier|Membre du set des 10 mots communs excÃ©dentaires|PubMed 15,1M|Kobak et al. 2025|ğŸŸ¢|
|**boast**|Verbe promotionnel|Z-score modifiÃ© â‰¥ 3,5 en 2024 (p < 0,001 pour le groupe)|PubMed 26,4M|Matsui, _Perspectives on Medical Education_ 14(1), 2025|ğŸŸ¢|
|**bolster**|Verbe amÃ©lioratif|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**unwavering**|Adjectif intensifier|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**transformative**|Adjectif promotionnel|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**elevate**|Verbe amÃ©lioratif|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**embark**|Verbe mÃ©taphorique|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**testament**|Nom Ã©valuatif|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**mitigate**|Verbe de hedging|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**navigate**|Verbe mÃ©taphorique|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**foster**|Verbe amÃ©lioratif|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**streamline**|Verbe d'efficience|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**holistic**|Adjectif de portÃ©e|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**imperative**|Adjectif d'urgence|Z-score modifiÃ© â‰¥ 3,5|PubMed 26,4M|Matsui 2025|ğŸŸ¢|
|**remarked**|Verbe de parole|**18Ã—** surreprÃ©sentation IA|Documents IA vs humains|GPTZero AI Vocabulary Scanner, 2024|ğŸŸ¡|
|**aligns**|Verbe corporatif|**16Ã—** surreprÃ©sentation IA|Documents IA vs humains|GPTZero 2024|ğŸŸ¡|
|**surpassing**|Verbe comparatif|**12Ã—** surreprÃ©sentation IA|Documents IA vs humains|GPTZero 2024|ğŸŸ¡|
|**tragically**|Adverbe Ã©motionnel|**11Ã—** surreprÃ©sentation IA|Documents IA vs humains|GPTZero 2024|ğŸŸ¡|
|**impacting**|Verbe (forme spÃ©cifique)|**11Ã—** surreprÃ©sentation IA|Documents IA vs humains|GPTZero 2024|ğŸŸ¡|

### Expressions et syntagmes avec donnÃ©es quantitatives

|Expression|CatÃ©gorie|DonnÃ©es quantitatives|Source|Preuve|
|---|---|---|---|---|
|**"plays a crucial/significant role in shaping"**|Formule Ã©valuative|**182Ã—** surreprÃ©sentation IA|GPTZero 2024 (Forbes)|ğŸŸ¡|
|**"notable works include"**|Formule biographique|**120Ã—**|GPTZero 2024|ğŸŸ¡|
|**"today's fast-paced world"**|Formule d'ouverture clichÃ©e|**107Ã—**|GPTZero 2024|ğŸŸ¡|
|**"aims to explore/enhance"**|Formule d'introduction|**50Ã—+**|GPTZero 2024|ğŸŸ¡|
|Co-occurrence de â‰¥2 mots parmi {intricate, meticulous, meticulously, commendable}|Combinaison marqueurs|**+468 %** en 2023|Gray 2024|ğŸŸ¢|
|**"in the ever-evolving landscape of"**|Formule mÃ©taphorique|Universellement citÃ©e|Praticiens multiples|ğŸ”´|
|**"it's important/worth noting that"**|Hedging formulaÃ¯que|Universellement citÃ©e|Praticiens + GPTZero|ğŸŸ¡|
|**"navigate the complexities of"**|MÃ©taphore du voyage|Universellement citÃ©e|Praticiens multiples|ğŸ”´|

### DonnÃ©es structurelles globales

L'Ã©tude Kobak et al. fournit le cadre quantitatif le plus solide : sur les 379 mots de style excÃ©dentaires identifiÃ©s en 2024, **66 % sont des verbes** et **14 % des adjectifs**. L'effet est inÃ©galement distribuÃ© gÃ©ographiquement : les articles de computation en provenance de Chine atteignent un taux estimÃ© de **~40 %** de traitement LLM (Î” = 0,41). Les journaux Ã  accÃ¨s ouvert comme MDPI et Frontiers montrent des taux nettement supÃ©rieurs Ã  la moyenne. Liang et al. confirment indÃ©pendamment que **jusqu'Ã  22,5 % des abstracts CS sur arXiv** et **6,5â€“16,9 % des peer reviews** dans les confÃ©rences IA sont substantiellement modifiÃ©s par LLM.

Un phÃ©nomÃ¨ne symÃ©trique mÃ©rite attention : Matsui (2025) documente des mots en **dÃ©clin** post-ChatGPT â€” "hypothesis," "results suggest," "all patients," "treatment of" â€” ainsi que les verbes basiques "is" et "are," ce qui suggÃ¨re que les LLM substituent un vocabulaire plus dense et plus abstrait au langage scientifique concret.

### Taxonomie fonctionnelle des marqueurs

Juzek & Ward (2025, COLING) identifient **21 mots focaux** via un pipeline systÃ©matique en trois Ã©tapes et attribuent le phÃ©nomÃ¨ne au **RLHF** : les annotateurs humains prÃ©fÃ¨rent inconsciemment les textes utilisant un registre soutenu, crÃ©ant une boucle de rÃ©troaction. Le survey de TerÄon (2025, arXiv:2510.05136) propose une taxonomie linguistique complÃ¨te des caractÃ©ristiques du texte IA, distinguant les niveaux lexical (diversitÃ© rÃ©duite, nominalisation accrue, moins de pronoms personnels), morpho-syntaxique (plus de relations auxiliaires/copules, plus de dÃ©terminants), et phrastique (variation de longueur rÃ©duite). Reinhart et al. (2025, _PNAS_) dÃ©montrent que **l'instruction tuning â€” et non l'architecture du modÃ¨le â€” est le facteur causal principal** de ce style distinctif, qui persiste mÃªme quand le modÃ¨le est invitÃ© Ã  Ã©crire de la fiction ou du dialogue informel.

---

## Section 2 â€” Inventaire lexical enrichi (franÃ§ais)

**âš  Avertissement mÃ©thodologique : aucune Ã©tude quantitative publiÃ©e ne fournit de ratios de surreprÃ©sentation mot par mot pour le franÃ§ais.** Les donnÃ©es ci-dessous reposent sur deux Ã©tudes acadÃ©miques avec volet franÃ§ais (sans quantification lexicale individuelle), des extrapolations de donnÃ©es anglaises, et des observations convergentes de praticiens francophones. Cette transparence est essentielle : le champ francophone accuse un retard de 2-3 ans sur la recherche anglophone en matiÃ¨re de dÃ©tection lexicale LLM.

### Ã‰tudes acadÃ©miques documentant le phÃ©nomÃ¨ne en franÃ§ais

Rigouts Terryn & de Lhoneux (2024, HumEval @ LREC-COLING 2024, pp. 12-27) ont comparÃ© ~550 textes journalistiques franÃ§ais humains vs. LLM (GPT-4, Zephyr) et trouvÃ© que **16 % des annotations d'erreurs linguistiques Ã©taient directement liÃ©es Ã  un transfert nÃ©gatif de l'anglais**. ğŸŸ¢ Les calques documentÃ©s incluent Â« faire du sens Â» (â† "to make sense") et Â« adresser un problÃ¨me Â» (â† "to address a problem"). Guo et al. (2024, arXiv:2410.15956, Inria Paris/Apple) mesurent une **divergence lexicale significative** entre sorties LLM et textes humains en franÃ§ais â€” supÃ©rieure Ã  celle observÃ©e en anglais â€” qu'ils qualifient d'Â« accent anglais Â» des LLM, manifestÃ© par des structures de phrases calquÃ©es sur l'anglais.

### Marqueurs franÃ§ais documentÃ©s par observations convergentes

|Mot/Expression|CatÃ©gorie|Statut des donnÃ©es|Sources|Preuve|
|---|---|---|---|---|
|**crucial**|Adj. emphatique|Equivalent direct du marqueur anglais documentÃ© (Î´ = 0,037 en EN)|BDM, Substack Daria, Redacteur.com, Excalibur, Flint.media|ğŸŸ¡|
|**essentiel**|Adj. emphatique|ObservÃ© par â‰¥3 sources FR indÃ©pendantes|BDM, TheConversation (Desagulier), pcexpertlemag|ğŸŸ¡|
|**fascinant**|Adj. emphatique|ObservÃ© par â‰¥3 sources FR|Substack Daria, Flint.media, Startups-nation|ğŸŸ¡|
|**incontournable**|Adj. emphatique|ObservÃ© FR|Excalibur 2025|ğŸŸ¡|
|**rÃ©volutionnaire**|Adj. hyperbolique|ObservÃ© FR|Substack Daria, Excalibur|ğŸŸ¡|
|**transformateur**|Adj. promotionnel|Calque de Â« transformative Â» (Z â‰¥ 3,5 en EN)|Substack Daria|ğŸŸ¡|
|**optimiser**|Verbe d'efficience|Â« UtilisÃ© Ã  toutes les sauces Â»|Excalibur 2025|ğŸŸ¡|
|**naviguer** (sens figurÃ©)|Verbe mÃ©taphorique|Calque de Â« navigate Â» (Z â‰¥ 3,5 en EN) ; observÃ© FR|Excalibur (Â« naviguer dans le paysage complexe Â»)|ğŸŸ¡|
|**libÃ©rer (le potentiel)**|Verbe promotionnel|Calque de Â« unlock the potential Â»|Excalibur|ğŸŸ¡|
|**plonger (dans)**|Verbe d'exploration|Calque de Â« delve Â» ; observÃ© FR indÃ©pendamment|Excalibur, BDM|ğŸŸ¡|
|**permettre de**|Verbe passe-partout|Suremploi documentÃ© FR|Substack Daria|ğŸŸ¡|
|**en outre**|Connecteur additif|Suremploi FR documentÃ©|BDM, Substack Daria|ğŸŸ¡|
|**nÃ©anmoins / cependant**|Connecteurs concessifs|Suremploi FR documentÃ©|Excalibur, BDM, Substack Daria|ğŸŸ¡|
|**par consÃ©quent**|Connecteur conclusif|Suremploi FR documentÃ©|Substack Daria|ğŸŸ¡|
|**il est important de noter que**|Formule introductive|ObservÃ© par â‰¥4 sources FR|BDM, pcexpertlemag, Substack Daria, Excalibur|ğŸŸ¡|
|**dans un monde qui Ã©volue Ã  un rythme effrÃ©nÃ©**|Formule d'ouverture|Analogue de Â« today's fast-paced world Â» (107Ã— en EN)|BDM|ğŸŸ¡|
|**Ã  l'Ã¨re de**|Formule d'ouverture|ObservÃ© FR|Flint.media|ğŸŸ¡|
|**une riche tapisserie de**|Calque mÃ©taphorique|Calque direct de Â« rich tapestry of Â»|Excalibur|ğŸŸ¡|
|**faire du sens**|Anglicisme syntaxique|**DocumentÃ© acadÃ©miquement** comme calque LLM|Rigouts Terryn & de Lhoneux 2024 (LREC-COLING)|ğŸŸ¢|
|**adresser un problÃ¨me**|Anglicisme syntaxique|**DocumentÃ© acadÃ©miquement**|Rigouts Terryn & de Lhoneux 2024|ğŸŸ¢|
|**tiret cadratin (â€”)**|Ponctuation|Suremploi reconnu par OpenAI, en cours de correction|Sam Altman (X), Lessentiel.lu, Substack Daria, Digitad.ca|ğŸŸ¡|

### Marqueurs structurels spÃ©cifiques au franÃ§ais

Au-delÃ  du vocabulaire, les praticiens francophones convergent sur plusieurs traits stylistiques systÃ©matiques : la **structure sandwich** (introduction + 3 points dÃ©veloppÃ©s + conclusion synthÃ©tique), l'absence quasi totale d'expressions idiomatiques familiÃ¨res (Â« Ã§a casse pas trois pattes Ã  un canard Â» remplacÃ© par des formules plates), l'uniformitÃ© de longueur des phrases, le **Â« lissage moral Â»** (clauses systÃ©matiques d'Ã©thique sur les sujets controversÃ©s : Â« Cependant, il est important de considÃ©rer l'Ã©thique... Â»), et la construction corrÃ©lative rÃ©currente Â« Non seulement X, mais Y Â». Le linguiste Guillaume Desagulier (The Conversation France, 2025) documente l'appauvrissement de la diversitÃ© lexicale et le recours systÃ©matique aux listes Ã  puces.

### Facteurs causaux spÃ©cifiques au franÃ§ais

Le biais anglophone des corpus d'entraÃ®nement est le facteur explicatif principal : Llama 3.1 utilise **92 % de donnÃ©es anglophones**. Les annotateurs RLHF pour le franÃ§ais sont souvent recrutÃ©s dans des pays francophones Ã  bas coÃ»t (Madagascar), produisant un franÃ§ais influencÃ© par l'anglais. Le phÃ©nomÃ¨ne de Â« translationese Â» â€” textes d'entraÃ®nement franÃ§ais souvent traduits de l'anglais â€” amplifie les calques syntaxiques. La tempÃ©rature basse par dÃ©faut favorise systÃ©matiquement les tokens les plus probables, renforÃ§ant les tics lexicaux.

---

## Section 3 â€” MÃ©thodologie et seuils de dÃ©tection

### Comment les chercheurs mesurent la surreprÃ©sentation

Quatre approches mÃ©thodologiques dominent le champ, chacune avec des forces et limites distinctes.

**L'approche Â« excÃ¨s de vocabulaire Â» de Kobak et al.** (la plus rigoureuse Ã  ce jour) s'inspire directement de l'Ã©pidÃ©miologie et de la mesure de la surmortalitÃ©. Pour chaque mot dans un corpus de 15,1 millions d'abstracts PubMed (2010-2024), deux mÃ©triques sont calculÃ©es : le **ratio de frÃ©quence** r = p/q (oÃ¹ p = frÃ©quence observÃ©e en 2024, q = frÃ©quence contrefactuelle extrapolÃ©e linÃ©airement depuis 2021-2022) et l'**Ã©cart de frÃ©quence** Î´ = p âˆ’ q. Le ratio r amplifie les mots rares dont la frÃ©quence explose (Â« delves Â» : r = 28,0), tandis que Î´ capture les mots courants dont la frÃ©quence augmente en valeur absolue (Â« potential Â» : Î´ = 0,052). Un mot est classÃ© Â« excÃ©dentaire Â» quand il franchit un seuil combinÃ© sur le plan (r, p) avec p > 10â»â´ (soit > 100 usages/an). Les 379 mots identifiÃ©s sont ensuite manuellement triÃ©s entre mots de contenu (liÃ©s aux sujets, ex. COVID) et **mots de style** (marqueurs LLM). Le code source est disponible sur GitHub (berenslab/llm-excess-vocab). ğŸŸ¢

**L'approche par suivi de mots-clÃ©s de Gray** est plus simple et reproductible : elle sÃ©lectionne des mots connus pour Ãªtre disproportionnellement prÃ©sents dans les sorties LLM, puis suit leur frÃ©quence annÃ©e par annÃ©e dans la base Dimensions (~5 millions d'articles). La comparaison se fait contre la variabilitÃ© historique 2015-2022. Un changement est considÃ©rÃ© significatif quand il excÃ¨de nettement la plage de variation normale. Gray montre que la combinaison de marqueurs amplifie massivement le signal : les articles contenant â‰¥2 mots parmi {intricate, meticulous, meticulously, commendable} augmentent de **+468 %** en 2023, un signal impossible Ã  attribuer au hasard. ğŸŸ¢

**Le modÃ¨le de mÃ©lange par maximum de vraisemblance de Liang et al.** traite la distribution des frÃ©quences de mots d'un corpus comme un mÃ©lange de texte humain et de texte LLM, estimant les proportions par maximum de vraisemblance. Cette approche nÃ©cessite un corpus de rÃ©fÃ©rence ground-truth (textes humains + textes IA) et utilise le **log odds ratio** pour identifier les mots les plus discriminants. Les quatre mots avec le log odds ratio le plus Ã©levÃ© sont : pivotal, intricate, showcasing, realm. ğŸŸ¢

**Le Z-score modifiÃ© de Matsui** applique une transformation Z-score sur 135 termes potentiellement influencÃ©s par l'IA dans 26,4 millions d'entrÃ©es PubMed, comparÃ©s Ã  84 phrases contrÃ´les via un modÃ¨le linÃ©aire Ã  effets mixtes (p < 0,001). Le seuil retenu est **Z â‰¥ 3,5**, atteint par 103 des 135 termes testÃ©s. La limite de cette mÃ©thode est que les termes candidats sont prÃ©-sÃ©lectionnÃ©s Ã  partir de discussions en ligne, introduisant un biais de sÃ©lection potentiel. ğŸŸ¢

### MÃ©thodes classiques de linguistique de corpus

Les outils traditionnels restent pertinents. Le **log-likelihood ratio** (GÂ², Dunning 1993, Rayson & Garside 2000) compare frÃ©quences observÃ©es et attendues entre corpus cible et corpus de rÃ©fÃ©rence, avec un seuil standard de GÂ² > 6,63 (p < 0,01) ou GÂ² > 15,13 (p < 0,0001). Il met en Ã©vidence les mots communs avec des diffÃ©rences de frÃ©quence. L'**odds ratio** mesure l'ampleur relative de la diffÃ©rence, mettant davantage en lumiÃ¨re les mots rares et spÃ©cialisÃ©s. Le **log ratio** (Hardie 2014) offre une interprÃ©tation intuitive : un log ratio de 1 = mot 2Ã— plus frÃ©quent, log ratio de 2 = 4Ã— plus frÃ©quent. Des outils comme AntConc, quanteda (R) et le package Python `keyness` implÃ©mentent ces calculs.

### Seuils pratiques pour la dÃ©tection

Ã€ l'Ã©chelle du corpus, Kobak utilise Î´ > 0,01 (1 point de pourcentage d'excÃ¨s) comme seuil minimal pour qualifier un mot d'excÃ©dentaire. Ã€ l'Ã©chelle d'un texte individuel, **aucun seuil publiÃ© ne dÃ©finit formellement Ã  partir de quelle densitÃ© de marqueurs un texte Â« sonne IA Â»**. Cependant, le rÃ©sultat de Gray sur les combinaisons est le plus opÃ©rationnel : la co-occurrence de **2+ marqueurs** dans un mÃªme article amplifie le signal de faÃ§on dramatique (+468 % pour deux mots, bien au-delÃ  de toute variation naturelle). L'implication pratique est qu'un auteur humain utilisant occasionnellement Â« crucial Â» ou Â« comprehensive Â» ne sera pas signalÃ© â€” c'est l'accumulation statistiquement improbable de ces termes qui trahit le traitement LLM.

### Outils de dÃ©tection et leur utilisation des marqueurs lexicaux

|Outil|Approche|Utilise des features lexicales ?|AccÃ¨s|
|---|---|---|---|
|**GLTR** (MIT/Harvard, 2019)|Classement de chaque token dans la distribution de prÃ©diction GPT-2 (top-10/100/1000)|Oui â€” rang du token mot par mot|Open source|
|**Ghostbuster** (UC Berkeley, NAACL 2024)|ProbabilitÃ©s unigrammes/trigrammes combinÃ©es via recherche structurÃ©e|**Oui explicitement** â€” unigrammes comme features|Open source|
|**DetectGPT** (Stanford, ICML 2023)|Courbure de la log-probabilitÃ© via perturbations|Non directement â€” opÃ¨re sur les log-probabilitÃ©s|Open source|
|**Binoculars** (ICML 2024)|Ratio perplexitÃ©/perplexitÃ© croisÃ©e entre deux LLM|Non â€” niveau perplexitÃ© globale|Open source|
|**GPTZero** (Princeton)|PerplexitÃ© + burstiness + 7 composantes propriÃ©taires|Partiellement â€” signale des mots spÃ©cifiques (Â« dive, Â» Â« landscape Â»)|Commercial|
|**Kobak excess-vocab**|Analyse de frÃ©quence de corpus|**Oui** â€” frÃ©quence brute par mot|Open source (GitHub + Zenodo)|

Ghostbuster est l'outil le plus directement pertinent pour la dÃ©tection basÃ©e sur la frÃ©quence lexicale : il intÃ¨gre explicitement un modÃ¨le unigramme et atteint **99,0 F1** en domaine, surpassant DetectGPT et GPTZero de 23,7 points F1 en moyenne. GLTR reste l'outil le plus pÃ©dagogique pour visualiser le phÃ©nomÃ¨ne mot par mot. Binoculars atteint les meilleures performances zero-shot : **>90 % de dÃ©tection Ã  un taux de faux positifs de 0,01 %**.

---

## Section 4 â€” Dynamique temporelle et variations inter-modÃ¨les

### Les marqueurs prÃ©coces dÃ©clinent, les marqueurs subtils persistent

L'Ã©tude la plus directement pertinente sur la dynamique temporelle est celle de Geng & Trotta (2025, arXiv:2502.09606, SISSA/Imperial College London), qui documente un phÃ©nomÃ¨ne de **coÃ©volution humain-LLM** dans l'Ã©criture acadÃ©mique. Les mots les plus ouvertement identifiÃ©s comme marqueurs LLM â€” Â« delve, Â» Â« intricate, Â» Â« realm Â» â€” ont atteint un pic dÃ©but 2024, puis **ont commencÃ© Ã  dÃ©cliner** aprÃ¨s que les chercheurs les ont publiquement signalÃ©s (mars-avril 2024). En revanche, des mots ChatGPT-favorisÃ©s qui se fondent dans le vocabulaire acadÃ©mique naturel â€” comme Â« significant, Â» Â« additionally, Â» Â« comprehensive Â» â€” **continuent d'augmenter** car ils sont plus difficiles Ã  identifier isolÃ©ment comme marqueurs. ğŸŸ¢

Mak & Walasek (2025, _Computers and Education: AI_) confirment cette dynamique dans le contexte Ã©tudiant : analysant 4 820 rapports d'Ã©tudiants de 2016 Ã  2025, ils observent que les marqueurs lexicaux ChatGPT ont **bondi en 2023-2024 puis dÃ©clinÃ© en 2025**, suggÃ©rant une adaptation active des utilisateurs. Le style est nÃ©anmoins devenu globalement plus formel, plus nominalisÃ© et plus positif en sentiment â€” et **les notes n'ont pas augmentÃ©** malgrÃ© ces changements lexicaux de surface. ğŸŸ¢

Certains mots que ChatGPT _dÃ©favorise_ subissent aussi un dÃ©clin mesurable : Â« is, Â» Â« are, Â» Â« therefore, Â» Â« hypothesis Â» perdent en frÃ©quence dans les abstracts PubMed de 2024, confirmant que l'influence LLM opÃ¨re dans les deux directions. ğŸŸ¢

### Empreintes distinctes par modÃ¨le

Plusieurs Ã©tudes dÃ©montrent que les LLM possÃ¨dent des signatures lexicales statistiquement distinguables entre eux. McGovern et al. (2024, arXiv:2405.14057) montrent qu'un simple classifieur n-grammes (GradientBoost) atteint un **F1 de 0,936 pour ChatGPT** et **0,920 pour Claude** dans une tÃ¢che d'identification multi-classes entre modÃ¨les. Ces empreintes sont persistantes au sein des familles de modÃ¨les (LLaMA-13b et LLaMA-65b produisent des distributions POS similaires) et **rÃ©sistent au changement de sujet**. ğŸŸ¢

Reinhart et al. (2025, _PNAS_ 122(8)) apportent l'explication causale la plus convaincante : **l'instruction tuning est le facteur principal** du style distinctif LLM, pas l'architecture ni la taille du modÃ¨le. Les modÃ¨les instruits produisent un style caractÃ©risÃ© par une densitÃ© informationnelle Ã©levÃ©e, davantage de nominalisations, plus de propositions participiales, plus de voix passive â€” un style qui persiste mÃªme quand le prompt demande de la fiction ou du dialogue informel. Les modÃ¨les de base (non instruits) diffÃ¨rent nettement moins de l'Ã©criture humaine. ğŸŸ¢

O'Sullivan et al. (2025, _Nature Humanities and Social Sciences Communications_) utilisent le Delta de Burrows sur des nouvelles littÃ©raires et montrent que les textes IA forment des **clusters serrÃ©s et uniformes** alors que les textes humains montrent une variation stylistique bien plus grande. GPT-4 montre une **cohÃ©rence interne supÃ©rieure** Ã  GPT-3.5 (cluster plus compact), ce qui le rend paradoxalement plus dÃ©tectable par stylomÃ©trie. ğŸŸ¢

### DiffÃ©rences qualitatives entre modÃ¨les

Les comparaisons qualitatives entre modÃ¨les restent principalement au niveau de l'observation praticienne. Claude est gÃ©nÃ©ralement perÃ§u comme produisant un texte plus Â« littÃ©raire Â» avec moins de buzzwords ; ChatGPT tend vers plus de formules transitionnelles (Â« furthermore, Â» Â« delve Â») et un ton plus conventionnellement enthousiaste ; Gemini favorise la concision et les listes Ã  puces. ğŸŸ¡ Une Ã©tude dans le domaine mÃ©dical (Krielke et al.) note que Gemini prÃ©fÃ¨re un vocabulaire plus accessible (Â« blood sugar Â») lÃ  oÃ¹ ChatGPT utilise le terme technique (Â« glucose Â»). ğŸŸ¡ Cependant, **aucune Ã©tude quantitative Ã  grande Ã©chelle ne compare directement les vocabulaires surreprÃ©sentÃ©s de GPT-4, Claude 3/3.5, et Gemini** avec la rigueur des Ã©tudes Kobak ou Gray. [LACUNE DOCUMENTÃ‰E]

### Ã‰volution par version de modÃ¨le

MiliÄka, MarklovÃ¡ & CvrÄek (2025, arXiv:2509.10179) appliquent le cadre dimensionnel de Biber et montrent que **tous les LLM dÃ©vient sur la dimension 1** (impliquÃ© vs. informationnel), produisant un texte plus dense en information â€” mais l'ampleur de cette dÃ©viation **varie significativement par modÃ¨le**. ğŸŸ¢ Les donnÃ©es spÃ©cifiques par version (GPT-3.5 â†’ GPT-4 â†’ GPT-4o â†’ GPT-5) restent fragmentaires. GPT-4o (mai 2024) a introduit un tokenizer Ã©largi (~200K vs. ~100K tokens), amÃ©liorant la reprÃ©sentation multilingue. OpenAI a reconnu travailler Ã  la correction du tiret cadratin et d'autres tics stylistiques. Mais aucune Ã©tude publiÃ©e ne documente une rÃ©duction quantitative des marqueurs lexicaux entre versions successives de GPT. [INCERTAIN]

### Le problÃ¨me de fond persiste

Le constat le plus important de Reinhart et al. est structurel : tant que le paradigme d'instruction tuning reste le mÃªme, les marqueurs fondamentaux â€” densitÃ© informationnelle Ã©levÃ©e, nominalisation, registre formel inadaptÃ©, manque de hedging Ã©pistÃ©mique authentique â€” **persisteront indÃ©pendamment des ajustements cosmÃ©tiques** sur des mots spÃ©cifiques comme Â« delve. Â» Les modÃ¨les peuvent apprendre Ã  Ã©viter les mots individuellement signalÃ©s, mais le biais stylistique profond crÃ©Ã© par le RLHF est un problÃ¨me architecturalement ancrÃ©. Les dÃ©tecteurs Ã©voluent en consÃ©quence : les outils de prochaine gÃ©nÃ©ration se concentrent moins sur des mots spÃ©cifiques et davantage sur les distributions de probabilitÃ© au niveau des tokens (Binoculars, Fast-DetectGPT) et les patterns structurels, anticipant un jeu du chat et de la souris oÃ¹ les marqueurs lexicaux Ã©vidents deviennent obsolÃ¨tes mais les signatures statistiques profondes demeurent.

---

## Conclusion

Trois constats Ã©mergent de cette synthÃ¨se. PremiÃ¨rement, le phÃ©nomÃ¨ne est **massif et quantifiÃ©** : 379 mots de style excÃ©dentaires, â‰¥13,5 % des publications biomÃ©dicales touchÃ©es, des ratios de surreprÃ©sentation allant de 10Ã— Ã  182Ã— pour certaines expressions. DeuxiÃ¨mement, la dynamique est **coÃ©volutive** : les marqueurs les plus visibles dÃ©clinent quand ils sont publiquement identifiÃ©s, mais des marqueurs plus subtils (mots courants lÃ©gÃ¨rement surreprÃ©sentÃ©s) prennent le relais et sont plus difficiles Ã  dÃ©tecter. TroisiÃ¨mement, le champ francophone prÃ©sente une **lacune criante** : aucune Ã©tude quantitative comparable aux travaux de Kobak, Gray ou Liang n'existe pour le franÃ§ais, malgrÃ© des observations convergentes de praticiens documentant un phÃ©nomÃ¨ne analogue aggravÃ© par le biais anglophone des corpus d'entraÃ®nement. L'explication causale la plus robuste pointe vers le RLHF comme mÃ©canisme amplificateur principal â€” un problÃ¨me qui ne se rÃ©soudra pas par le simple filtrage de listes de mots, mais qui nÃ©cessite des changements dans les mÃ©thodologies d'alignement elles-mÃªmes.