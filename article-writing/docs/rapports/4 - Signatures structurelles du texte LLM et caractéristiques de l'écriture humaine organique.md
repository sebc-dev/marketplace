# Signatures structurelles du texte LLM et caractÃ©ristiques de l'Ã©criture humaine organique

Les textes gÃ©nÃ©rÃ©s par LLM prÃ©sentent des **signatures structurelles quantifiables et rÃ©currentes** â€” uniformitÃ© de longueur phrastique, prÃ©dominance de relations d'Ã‰laboration dans la structure discursive, rigiditÃ© des templates organisationnels â€” que la recherche empirique distingue dÃ©sormais de l'Ã©criture humaine avec une fiabilitÃ© croissante mais non absolue. La burstiness (variabilitÃ© de complexitÃ© phrastique) reste un signal utile mais insuffisant seul, biaisÃ© contre les locuteurs non natifs. Les modÃ¨les rÃ©cents (GPT-4o, Claude 3.5) sont structurellement moins prÃ©visibles que leurs prÃ©dÃ©cesseurs, mais conservent des empreintes identifiables â€” chaque famille de LLM possÃ¨de une "empreinte stylistique" distincte, confirmÃ©e par des Ã©tudes Ã  grande Ã©chelle. La littÃ©rature francophone sur ce sujet est embryonnaire : aucune Ã©tude acadÃ©mique franÃ§aise ne traite spÃ©cifiquement des patterns structurels du texte IA en franÃ§ais.

---

## Section 1 â€” Signatures structurelles documentÃ©es

| Pattern structurel                                    | Description                                                                                                                                                                                                                                | Source (auteur, date, type)                                                                                                                | MÃ©trique si disponible                                                                                                                                                             | Niveau de preuve                                              |
| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- |
| **Distribution Ã©troite des longueurs de phrase**      | Les LLM produisent des phrases concentrÃ©es dans la plage 10-30 tokens, avec variance rÃ©duite. Les humains montrent une distribution plus Ã©talÃ©e incluant davantage de phrases >40 tokens.                                                  | MuÃ±oz-Ortiz, GÃ³mez-RodrÃ­guez, Vilares â€” _Artificial Intelligence Review_ 57, 265 (2024) ; arXiv 2308.09067                                 | Histogrammes de distribution de longueur de phrase (tokens/phrase) ; Ã©cart moyen humain > Ã©cart moyen LLM sur 6 modÃ¨les testÃ©s                                                     | **Empirique** â€” Ã©tude large-scale, 6 LLM, peer-reviewed       |
| **PrÃ©dominance des relations d'Ã‰laboration (RST)**    | Dans l'analyse par Rhetorical Structure Theory, les textes LLM montrent une surreprÃ©sentation des relations d'Ã‰laboration, tandis que les textes humains utilisent davantage de relations Joint (ramification discursive plus Ã©quilibrÃ©e). | Â« Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs Â» â€” arXiv 2402.10586 (fÃ©v. 2024)                         | FrÃ©quence des motifs discursifs extraits d'arbres RST transformÃ©s en hypergraphes rÃ©cursifs ; motif index 0 (Elaboration) = signal machine ; motif index 5 (Joint) = signal humain | **Empirique** â€” analyse quantitative avec classificateurs     |
| **Perte de cohÃ©rence discursive en document long**    | Les LLM segmentent les textes en blocs traitÃ©s sÃ©quentiellement, perdant la cohÃ©rence thÃ©matique centrale. Les humains maintiennent un fil directeur stable sur l'ensemble du document.                                                    | Â« Discourse Features Enhance Detection of Document-Level Machine-Generated Content Â» â€” arXiv 2412.12679 (dÃ©c. 2024)                        | Score DTransformer combinant features PDTB et sÃ©mantiques                                                                                                                          | **Empirique** â€” nouveau dataset (paraLFQA, paraWP)            |
| **Absence de variation de registre selon le genre**   | Les LLM instruction-tuned produisent un style informationnellement dense et nominal quel que soit le genre textuel demandÃ©. Ils ne s'adaptent pas aux conventions de registre (formel vs informel).                                        | Reinhart, Markey et al. (Carnegie Mellon) â€” _PNAS_ 122(8), e2422455122 (fÃ©v. 2025) ; arXiv 2410.16107                                      | Features de Biber (grammaticales et rhÃ©toriques) ; matrice de confusion bloc-diagonale dans classificateur Random Forest                                                           | **Empirique** â€” PNAS peer-reviewed, deux corpus parallÃ¨les    |
| **ComplexitÃ© syntaxique excessive et nominalisation** | ChatGPT produit des phrases avec une profondeur d'arbre de dÃ©pendance supÃ©rieure (GPT-3 : 6.18, GPT-4 : 5.94 vs humains : 5.72) et davantage de propositions subordonnÃ©es (2.31/2.08 vs 1.81). Usage accru de nominalisations.             | Herbold, Hautli-Janisz et al. â€” _Scientific Reports_ 13, 18617 (2023) ; arXiv 2304.14276                                                   | Profondeur d'arbre de dÃ©pendance (spaCy) ; nombre de propositions subordonnÃ©es ; frÃ©quence de nominalisations                                                                      | **Empirique** â€” Nature Scientific Reports, large-scale corpus |
| **Distribution symÃ©trique du surprisal**              | Le texte IA produit des distributions de surprisal par token plus symÃ©triques (skewness faible). Le texte humain montre une skewness positive (tokens rares, surprenants) et une kurtosis plus Ã©levÃ©e (queues lourdes).                    | Framework DivEye â€” arXiv 2509.18880 (2025)                                                                                                 | Skewness (Î³â‚) et Kurtosis (Î³â‚‚) des distributions de surprisal par token                                                                                                            | **Empirique** â€” testÃ© sur 12 modÃ¨les, 8 domaines              |
| **Template paragraphique tripartite**                 | Les paragraphes IA suivent un schÃ©ma rigide : phrase gÃ©nÃ©rale/introductive â†’ information utile centrale â†’ phrase de clÃ´ture gÃ©nÃ©raliste. Structure identique rÃ©pÃ©tÃ©e paragraphe aprÃ¨s paragraphe.                                          | StÃ©phane Torregrosa, Squid-Impact (sept. 2025) ; Pangram Labs, Bradley Emi (avr. 2025) ; Elizabeth Steere, _Inside Higher Ed_ (juil. 2024) | Non formalisÃ© quantitativement                                                                                                                                                     | **Observationnel** â€” convergence de multiples praticiens      |
| **Ouvertures de paragraphes formulaÃ¯ques**            | Les paragraphes IA commencent par un ensemble restreint de transitions : Â« Furthermore Â», Â« Moreover Â», Â« Overall Â», Â« Additionally Â». En franÃ§ais : Â« De surcroÃ®t Â», Â« En somme Â», Â« Tout d'abordâ€¦ Ensuiteâ€¦ En conclusion Â».              | Elizabeth Steere, _Inside Higher Ed_ (juil. 2024) â€” analyse de 50+ essais IA ; Blog du ModÃ©rateur (FR)                                     | FrÃ©quence comparÃ©e des connecteurs d'ouverture (humain vs IA)                                                                                                                      | **Empirique** â€” Ã©tude systÃ©matique de 50+ essais              |
| **Structure list-like et sous-sections excessives**   | Les LLM insÃ¨rent des listes Ã  puces, des sous-titres numÃ©rotÃ©s et des bullet points dans des genres textuels oÃ¹ les humains n'en utilisent jamais (essai formel, prose argumentative).                                                     | Pangram Labs (avr. 2025) ; Steere (juil. 2024) ; Wikipedia: Signs of AI Writing                                                            | Non formalisÃ©                                                                                                                                                                      | **Observationnel** â€” multiples praticiens concordants         |
| **Conclusions disproportionnÃ©es et rÃ©pÃ©titives**      | Les conclusions IA sont anormalement longues, commencent par Â« Overall Â» / Â« In conclusion Â» / Â« En somme Â», et restituent mÃ©caniquement le contenu dÃ©jÃ  Ã©noncÃ©. Les conclusions humaines sont plus courtes et ajoutent une perspective.   | Pangram Labs (avr. 2025) ; Compilatio (FR)                                                                                                 | Ratio longueur conclusion / longueur corps de texte                                                                                                                                | **Observationnel** â€” praticiens, non quantifiÃ© formellement   |
| **EntrÃ©e directe dans le sujet (absence de warm-up)** | Les essais IA abordent immÃ©diatement le sujet. L'Ã©criture humaine utilise des entrÃ©es graduelles : anecdotes, dÃ©finitions, questions rhÃ©toriques avant d'arriver Ã  la thÃ¨se.                                                               | Steere, _Inside Higher Ed_ (juil. 2024)                                                                                                    | Non formalisÃ©                                                                                                                                                                      | **Empirique** â€” comparaison systÃ©matique                      |
| **Distances de dÃ©pendance sous-optimales**            | Les LLM produisent des distances de dÃ©pendance syntaxique moins optimisÃ©es que les humains (plus Ã©loignÃ©es du minimum thÃ©orique), Ã  l'exception de Falcon.                                                                                 | MuÃ±oz-Ortiz et al. (2024)                                                                                                                  | Distance de dÃ©pendance moyenne (Mean Dependency Distance)                                                                                                                          | **Empirique**                                                 |
| **Moins de marqueurs Ã©pistÃ©miques et modaux**         | Les textes IA contiennent moins de verbes modaux, moins de hedges, et moins de marqueurs de discours que l'Ã©criture humaine â€” signes d'une argumentation moins nuancÃ©e.                                                                    | Herbold et al. (2023) ; Frontiers in Education (2024)                                                                                      | FrÃ©quence des marqueurs de modalitÃ© et de discours                                                                                                                                 | **Empirique**                                                 |
| **Persistance de la troisiÃ¨me personne**              | MÃªme sur des questions personnelles ou de type reader-response, l'IA reste en troisiÃ¨me personne et Ã©vite le Â« je Â».                                                                                                                       | Steere, _Inside Higher Ed_ (juil. 2024)                                                                                                    | Non formalisÃ©                                                                                                                                                                      | **Empirique** â€” comparaison systÃ©matique                      |
| **Usage excessif du tiret cadratin (em dash)**        | Les LLM surutilisent le tiret cadratin (â€”) comme Ã©lÃ©ment structurel pour insÃ©rer des clauses explicatives ou des pauses dramatiques.                                                                                                       | REM Web Solutions ; Pangram Labs (2025)                                                                                                    | Non formalisÃ©                                                                                                                                                                      | **Observationnel** â€” source unique corroborÃ©e                 |
| **Sous-titres gÃ©nÃ©riques**                            | Les LLM produisent des sous-titres interchangeables suivant des formules rÃ©currentes : Â« Understanding X Â», Â« The Importance of Y Â», Â« The Future of Z Â», Â« What Is X? Â», Â« Key Takeaways Â». En franÃ§ais : Â« Comprendre X Â», Â« L'importance de Y Â», Â« L'avenir de Z Â». Les titres Ã  deux-points (Â« Digital Marketing in 2025: Trends, Tools, and Tactics Â») sont Ã©galement sur-reprÃ©sentÃ©s car le format dÃ©crit nettement le sujet â€” les humains expriment davantage un jugement, une implication ou une tension. | Bouchard, _Towards AI_ (janv. 2026) ; TRO Agency (2025) ; BlueMagnet (2026) | Non formalisÃ© quantitativement | **Observationnel** â€” convergence de multiples praticiens |
| **Annonces de plan et signposting mÃ©tatextuel**       | Les LLM surreprÃ©sentent le mÃ©tadiscours interactif (annonces d'objectifs, sÃ©quenÃ§age, marqueurs endophoriques) : Â« In this article, we willâ€¦ Â», Â« Firstâ€¦ thenâ€¦ finally Â», Â« Now that we've explored Xâ€¦ Â». ParallÃ¨lement, ils sous-reprÃ©sentent le mÃ©tadiscours interactionnel (hedges, boosters, marqueurs d'attitude). L'IA Ã©crit *sur* l'article plutÃ´t que *sur* le sujet, et ce signposting persiste tout au long du document. En franÃ§ais, l'annonce de plan est une convention acadÃ©mique lÃ©gitime (Â« annonce du plan Â»), rendant ce signal plus ambigu. | Jiang & Hyland, _English for Specific Purposes_ (2025) ; Bouchard, _Towards AI_ (janv. 2026) ; TRO Agency (2025) | Ratio mÃ©tadiscours interactif / interactionnel (cadre de Hyland 2005) | **Empirique** â€” publication peer-reviewed ESP, corroborÃ©e par praticiens |
| **Â« Unearned profundity Â»**                           | Phrases dramatiques sans substance insÃ©rÃ©es pour crÃ©er un effet de profondeur : Â« Something shifted. Â», Â« Everything changed. Â», Â« But here's the thing. Â» CombinÃ©es avec des triades percutantes (Â« Fast, efficient, and reliable. Â»). | Charlie Guo, _The Field Guide to AI Slop_ (oct. 2025) | Non formalisÃ© | **Observationnel** â€” source unique mais dÃ©taillÃ©e |
| **Artefacts de formatage Unicode**                    | Usage de caractÃ¨res Unicode stylistiques dans des contextes professionnels : flÃ¨ches (â†’), signes de multiplication (Ã—), caractÃ¨res gras Unicode (ğ—¯ğ—¼ğ—¹ğ—±), emojis en guise de puces. Atypique de l'Ã©criture humaine professionnelle. | Guo, _The Field Guide to AI Slop_ (oct. 2025) | Non formalisÃ© | **Observationnel** â€” source unique |
| **Noms fictifs stÃ©rÃ©otypÃ©s**                          | 60-70% des noms dans les exemples fictifs de ChatGPT et Claude sont Â« Emily Â» ou Â« Sarah Â». Les humains puisent dans un rÃ©pertoire de noms plus divers et souvent culturellement situÃ©. | Pangram Labs (2025) | FrÃ©quence des prÃ©noms dans les exemples fictifs | **Observationnel** â€” source unique |

### Exemples illustratifs par pattern

Chaque paire ci-dessous est un exemple construit pour dÃ©montrer le pattern. La version IA illustre le signal structurel ; la version humaine illustre l'Ã©criture organique correspondante.

**#1 â€” Distribution Ã©troite des longueurs de phrase**

> *IA :* "Machine learning models require large datasets. These datasets must be carefully curated. Data quality directly impacts model performance. Poor data leads to unreliable predictions. Regular validation helps maintain accuracy."
>
> *Humain :* "You need data â€” lots of it. But here's the thing most tutorials won't tell you: a small, clean dataset almost always beats a massive, noisy one. I learned this the hard way after spending three weeks scraping Reddit."

> *IA (FR) :* Â« Les modÃ¨les d'apprentissage automatique nÃ©cessitent de grands jeux de donnÃ©es. Ces donnÃ©es doivent Ãªtre soigneusement prÃ©parÃ©es. La qualitÃ© des donnÃ©es impacte directement les performances. Â»
>
> *Humain (FR) :* Â« Il faut des donnÃ©es. Beaucoup. Mais pas n'importe lesquelles â€” un petit dataset propre bat presque toujours un gros dataset bruitÃ©. J'ai mis trois semaines Ã  le comprendre. Â»

**#2 â€” PrÃ©dominance Ã‰laboration RST**

> *IA :* "Transfer learning is a powerful technique. It allows models to leverage knowledge from one task to improve performance on another. This approach is particularly useful when labeled data is scarce. By using pre-trained models, researchers can significantly reduce training time."
>
> *Humain :* "Transfer learning sounds great in theory, but watch out: fine-tuning BERT on 200 medical records gave us worse F1 than training a simple logistic regression from scratch. The domain gap was just too wide."

**#3 â€” Perte de cohÃ©rence en document long**

> *IA (paragraphe 12 d'un article) :* "The system processes input data through multiple layers. Each layer extracts increasingly abstract features." [Sans rÃ©fÃ©rence au pipeline custom dÃ©crit au paragraphe 3]
>
> *Humain (paragraphe 12) :* "Remember the three-stage pipeline from earlier? This is where stage two â€” the feature extraction we spent so long debugging â€” finally pays off."

**#4 â€” Absence de variation de registre**

> *IA :* "The deployment process involves several critical steps. First, the container image must be built. Subsequently, the orchestration layer must be configured. Finally, monitoring must be established."
>
> *Humain :* "Deployment is straightforward â€” in theory. Build the image, configure k8s, set up monitoring. In practice? Our first deploy took six hours because someone forgot to set the memory limit. Don't be that person."

**#5 â€” ComplexitÃ© syntaxique excessive**

> *IA :* "The implementation of microservices architecture, which has been increasingly adopted by organizations seeking to enhance their scalability and maintainability, necessitates a comprehensive understanding of distributed systems principles."
>
> *Humain :* "Microservices look simple on the whiteboard. Then you deploy them and discover you've traded one monolith for fifty tiny problems that all fail differently."

**#6 â€” Template paragraphique tripartite**

> *IA :* "Containerization has revolutionized software deployment. By packaging applications with their dependencies, containers ensure consistency across environments. This approach has become essential for modern DevOps practices."
>
> *Humain :* "Containers solve the 'works on my machine' problem. Mostly. You'll still hit edge cases with GPU drivers and filesystem permissions that make you question your career choices."

**#7 â€” Ouvertures formulaÃ¯ques**

> *IA :* "In today's rapidly evolving technological landscape, artificial intelligence has emerged as a transformative force that is reshaping industries across the globe."
>
> *Humain :* "Last Tuesday, our image classifier flagged a chihuahua as a blueberry muffin. Again. That's when I decided to rewrite the preprocessing pipeline."

> *IA (FR) :* Â« Dans le paysage technologique en constante Ã©volution, l'intelligence artificielle s'est imposÃ©e comme une force transformatrice. Â»
>
> *Humain (FR) :* Â« Mardi dernier, notre classifieur a confondu un chihuahua avec un muffin. Pour la troisiÃ¨me fois. J'ai refait le pipeline. Â»

**#8 â€” Structure list-like excessive**

> *IA :* "Key benefits of TypeScript include: 1) Static type checking 2) Better IDE support 3) Improved code maintainability 4) Enhanced refactoring capabilities 5) Better documentation through types."
>
> *Humain :* "TypeScript caught a bug in production code that had been hiding for months â€” a function expected a string but got undefined. That alone justified the migration. The IDE autocomplete is a nice bonus."

**#9 â€” Conclusions rÃ©pÃ©titives**

> *IA :* "In conclusion, as we have seen throughout this article, microservices architecture offers significant advantages in terms of scalability, maintainability, and deployment flexibility. By adopting microservices, organizations can achieve greater agility."
>
> *Humain :* "So: use microservices if your team is big enough to own them independently. Otherwise, a well-structured monolith will serve you better and let you sleep at night."

**#10 â€” EntrÃ©e directe dans le sujet**

> *IA :* "React is a JavaScript library for building user interfaces. It was developed by Facebook and is maintained by Meta. React uses a virtual DOM for efficient rendering."
>
> *Humain :* "I switched our dashboard from jQuery spaghetti to React last quarter. Here's what I wish someone had told me before I started."

**#11 â€” Persistance de la 3e personne**

> *IA :* "Developers should consider implementing error boundaries in their React applications. When a component throws an error, the error boundary catches it and displays a fallback UI."
>
> *Humain :* "I wrap every route-level component in an error boundary now. I used to skip it, thinking 'my code won't crash.' It does. It always does."

**#12 â€” Usage excessif du em dash**

> *IA :* "The framework â€” which was originally designed for mobile applications â€” has evolved into a comprehensive solution â€” one that addresses both frontend and backend concerns â€” making it ideal for full-stack development."
>
> *Humain :* "The framework started as a mobile toolkit. Over time, it grew to cover the full stack. That's both its strength and its biggest source of complexity."

**#13 â€” Moins de marqueurs Ã©pistÃ©miques**

> *IA :* "This approach significantly reduces latency. The results demonstrate clear improvements in throughput. The architecture provides robust fault tolerance."
>
> *Humain :* "We think this cuts latency, though our benchmarks are probably too synthetic to be sure. Throughput looks better, at least in our tests. Fault tolerance? Honestly, we haven't stress-tested it enough to say."

**#14 â€” Burstiness basse** â€” La burstiness se manifeste Ã  l'Ã©chelle du document entier. Pour l'illustrer, comparer les cinq premiÃ¨res phrases d'un article :

> *IA :* Cinq phrases consÃ©cutives de 14, 16, 15, 17, 14 tokens (CV â‰ˆ 0.08).
>
> *Humain :* Cinq phrases de 4, 32, 8, 45, 6 tokens (CV â‰ˆ 0.85). L'alternance entre fragments percutants et dÃ©veloppements longs crÃ©e le Â« rythme Â» organique.

---

## Section 2 â€” MÃ©triques quantitatives de rÃ©gularitÃ©

### 2.1 Burstiness (variabilitÃ© phrastique)

**DÃ©finition :** Mesure de la variation des patterns d'Ã©criture et des perplexitÃ©s par phrase sur l'ensemble d'un document. Une burstiness basse signifie une construction phrastique uniforme (signal IA) ; une burstiness haute signifie une alternance entre phrases simples et complexes (signal humain).

**ImplÃ©mentation GPTZero (code open-source initial) :**

```
Burstiness = max(perplexitÃ©_par_phrase)
PerplexitÃ©_moyenne = Î£(perplexitÃ©_par_phrase) / N
```

Le modÃ¨le de production actuel de GPTZero est plus sophistiquÃ©, intÃ©grant la burstiness comme l'un de **7 composants** de dÃ©tection.

**Utilisateurs commerciaux :** GPTZero (composant explicite), QuillBot, Originality.ai (composant signalÃ©). Turnitin considÃ¨re explicitement la burstiness comme **insuffisante** et utilise un transformeur profond capturant des dÃ©pendances statistiques de plus haut ordre.

**RÃ©fÃ©rence :** GPTZero (gptzero.me/news/perplexity-and-burstiness-what-is-it/) ; code GitHub BurhanUlTayyab/GPTZero.

**Niveau de confiance :** Ã‰levÃ© pour l'existence du signal, Moyen pour sa fiabilitÃ© isolÃ©e.

### 2.2 PerplexitÃ© et courbure de probabilitÃ©

**PerplexitÃ© :** PP = 2^(-1/N Ã— Î£ logâ‚‚ P(táµ¢ | tâ‚...táµ¢â‚‹â‚)). Le texte IA a une perplexitÃ© plus basse (plus prÃ©visible) que le texte humain. UtilisÃ©e par la quasi-totalitÃ© des dÃ©tecteurs.

**Courbure de probabilitÃ© (DetectGPT) :** d(x, p_Î¸, q) = [log p_Î¸(x) âˆ’ E_{xÌƒâˆ¼q(Â·|x)} log p_Î¸(xÌƒ)] / Ïƒ_{xÌƒâˆ¼q(Â·|x)} log p_Î¸(xÌƒ). Le texte machine occupe les rÃ©gions de **courbure nÃ©gative** de la fonction de log-probabilitÃ©. Mitchell et al., ICML 2023 (arXiv 2301.11305).

**Fast-DetectGPT :** Courbure conditionnelle ; texte machine â‰ˆ 3, texte humain â‰ˆ 0. AmÃ©lioration de ~75% sur DetectGPT. Bao et al., ICLR 2024 (arXiv 2310.05130).

**Niveau de confiance :** Ã‰levÃ© â€” publications ICML et ICLR peer-reviewed.

### 2.3 Statistiques d'ordre supÃ©rieur du surprisal (DivEye)

**MÃ©triques :** Skewness (Î³â‚) et Kurtosis (Î³â‚‚) des distributions de surprisal par token. Le texte IA produit des distributions plus **symÃ©triques** (skewness basse) ; le texte humain montre une **skewness positive** (prÃ©sence de tokens rares) et une **kurtosis Ã©levÃ©e** (comportement Ã  queues lourdes reflÃ©tant la diversitÃ© stylistique).

**RÃ©fÃ©rence :** arXiv 2509.18880 (2025). RÃ©sultats compÃ©titifs sur 12 modÃ¨les, 8 domaines, 4 stratÃ©gies de dÃ©codage.

**DÃ©tecteurs commerciaux :** Non confirmÃ© dans les outils commerciaux actuels. Approche acadÃ©mique rÃ©cente.

**Niveau de confiance :** Moyen â€” prÃ©publication, non encore adoptÃ©e par les outils commerciaux.

### 2.4 Distribution de longueur de phrase

**MÃ©thode :** Histogrammes de tokens par phrase ; coefficient de variation (CV = Ïƒ/Î¼) de la longueur de phrase ; mesures de diversitÃ© textuelle (STTR, MTLD). Les LLM concentrent les phrases dans la plage 10-30 tokens avec une variance plus faible. Les humains produisent une distribution plus large avec plus de phrases longues (>40 tokens).

**RÃ©fÃ©rence :** MuÃ±oz-Ortiz et al. (2024), _Artificial Intelligence Review_.

**DÃ©tecteurs commerciaux :** QuillBot et NetusAI mentionnent explicitement la variation de longueur de phrase. Copyleaks analyse la Â« dispersion syllabique Â».

**Niveau de confiance :** Ã‰levÃ©.

### 2.5 MÃ©triques de complexitÃ© syntaxique

**MÃ©thode :** Profondeur de l'arbre de dÃ©pendance (via parseur spaCy) ; nombre de propositions subordonnÃ©es ; distance de dÃ©pendance moyenne ; frÃ©quence des nominalisations.

**RÃ©fÃ©rence :** Herbold et al. (2023), _Scientific Reports_.

**DÃ©tecteurs commerciaux :** Copyleaks utilise l'analyse POS (parties du discours). Compilatio (FR) analyse Â« la construction des phrases Â».

**Niveau de confiance :** Ã‰levÃ©.

### 2.6 FrÃ©quence des motifs discursifs (RST)

**MÃ©thode :** Extraction de motifs discursifs Ã  partir d'arbres RST transformÃ©s en hypergraphes rÃ©cursifs. Distribution de frÃ©quence des motifs comparÃ©e entre texte humain et machine.

**RÃ©fÃ©rence :** arXiv 2402.10586 (2024).

**DÃ©tecteurs commerciaux :** Non signalÃ© dans les outils commerciaux. Approche acadÃ©mique.

**Niveau de confiance :** Moyen â€” une seule Ã©tude utilisant cette mÃ©trique spÃ©cifique.

### 2.7 Ratio contenu/fonction et POS bigrams

**MÃ©thode :** Ratio mots de contenu / mots-outils. Les humains moyennent 0.98, l'IA moyenne **1.37** â€” crÃ©ant une Â« lourdeur Â» informationnelle dans le texte IA. Les POS bigrams (bigrammes de parties du discours) sont hautement discriminants pour l'identification du modÃ¨le source.

**RÃ©fÃ©rence :** MultiLingual Magazine (sept. 2025) pour le ratio ; McGovern et al., COLING 2025 pour les POS bigrams.

**Niveau de confiance :** Moyen pour le ratio (source magazine) ; Ã‰levÃ© pour les POS bigrams (peer-reviewed).

---

## Section 3 â€” CaractÃ©ristiques de l'Ã©criture humaine organique

Pour chaque signature IA identifiÃ©e, voici le comportement humain correspondant documentÃ© dans la littÃ©rature.

**Distribution Ã©troite des longueurs de phrase (IA)** â†’ L'Ã©criture humaine produit une **distribution Ã©talÃ©e et Ã  queues lourdes** : alternance naturelle entre phrases trÃ¨s courtes (3-5 mots, pour l'emphase) et phrases longues et complexes (40+ tokens, pour le raisonnement dÃ©taillÃ©). Cette variabilitÃ© crÃ©e un rythme organique que les lecteurs perÃ§oivent inconsciemment. | MuÃ±oz-Ortiz et al. (2024)

**PrÃ©dominance de l'Ã‰laboration discursive (IA)** â†’ Les humains utilisent une **structure discursive plus ramifiÃ©e** avec davantage de relations Joint (coordination), crÃ©ant un discours qui bifurque, digresse, et revient â€” plutÃ´t qu'un empilement linÃ©aire d'Ã©laborations. L'arbre discursif humain est plus large et moins profond. | arXiv 2402.10586

**Perte de cohÃ©rence en document long (IA)** â†’ Les Ã©crivains humains experts maintiennent un **fil thÃ©matique central** Ã  travers le document entier, avec des digressions contrÃ´lÃ©es qui reviennent au thÃ¨me principal. La cohÃ©rence humaine est tissÃ©e, non segmentÃ©e. | arXiv 2412.12679

**Absence de variation de registre (IA)** â†’ L'Ã©criture humaine **adapte spontanÃ©ment le registre** au genre et au contexte : plus nominale et dense pour un article scientifique, plus verbale et impliquÃ©e pour un billet de blog, plus familiÃ¨re pour une conversation. Les features de Biber montrent des profils rhÃ©toriques distincts par genre chez les humains, convergents chez l'IA. | Reinhart et al., PNAS (2025)

**ComplexitÃ© syntaxique excessive (IA)** â†’ L'Ã©criture humaine exhibe une **complexitÃ© syntaxique modÃ©rÃ©e mais variable** : des phrases simples cÃ´toient des constructions Ã©laborÃ©es selon le besoin communicatif. Les humains utilisent plus de **verbes modaux et marqueurs Ã©pistÃ©miques** (Â« perhaps Â», Â« might suggest Â», Â« il semblerait Â») qui tÃ©moignent d'une pensÃ©e en cours plutÃ´t que d'une assertion aplatie. | Herbold et al. (2023)

**Template paragraphique tripartite (IA)** â†’ Les paragraphes humains ont des **longueurs et structures irrÃ©guliÃ¨res** : un paragraphe d'une phrase pour l'emphase, suivi d'un paragraphe de 8 phrases pour dÃ©velopper une preuve, puis un paragraphe moyen avec un twist argumentatif. La structure sert le propos, non un template. | Pangram Labs (2025) ; Steere (2024)

**Ouvertures formulaÃ¯ques (IA)** â†’ Les humains commencent les paragraphes de maniÃ¨re **diverse et contextuelle** : par un exemple concret, une question, un fait surprenant, un fragment, une rÃ©fÃ©rence au paragraphe prÃ©cÃ©dent â€” rarement par un connecteur logique formel isolÃ©. | Steere, _Inside Higher Ed_ (2024)

**EntrÃ©e directe dans le sujet (IA)** â†’ L'Ã©criture humaine, notamment les essais et billets de blog, comporte une **entrÃ©e graduelle** : anecdote personnelle, question ouverte, scÃ¨ne, ou dÃ©finition problÃ©matisÃ©e avant d'arriver Ã  la thÃ¨se. Tom Johnson note que l'alternance entre narration personnelle (premiÃ¨re personne) et explication (troisiÃ¨me personne) est un marqueur fort d'authenticitÃ©. | Steere (2024) ; Tom Johnson, idratherbewriting.com (oct. 2023)

**Persistance de la troisiÃ¨me personne (IA)** â†’ Les Ã©crivains humains **alternent les voix narratives** selon le besoin rhÃ©torique : premiÃ¨re personne pour l'expÃ©rience vÃ©cue, troisiÃ¨me pour l'analyse, deuxiÃ¨me pour l'adresse au lecteur. Cette alternance est rare dans le texte IA non promptÃ©. | Steere (2024)

**Distribution symÃ©trique du surprisal (IA)** â†’ Le texte humain contient des **pics de surprisal** â€” mots rares, tournures inattendues, mÃ©taphores originales â€” qui crÃ©ent une distribution Ã  skewness positive. Ces Â« aspÃ©ritÃ©s stylistiques Â» sont ce qui donne au texte sa texture unique et reconnaissable. | DivEye, arXiv 2509.18880

**Conclusions longues et rÃ©pÃ©titives (IA)** â†’ Les conclusions humaines sont typiquement **plus courtes que les conclusions IA** et ajoutent une perspective nouvelle, une question ouverte, ou un retournement â€” plutÃ´t que de rÃ©sumer mÃ©caniquement le contenu prÃ©cÃ©dent. | Pangram Labs (2025)

**Sous-titres gÃ©nÃ©riques (IA)** â†’ Les Ã©crivains humains crÃ©ent des titres qui expriment un **jugement, une implication ou une tension** : Â« Why your deployment pipeline is lying to you Â», Â« The hidden cost of microservices Â» plutÃ´t que Â« Understanding Deployment Pipelines Â» ou Â« The Importance of Microservices Â». Les titres humains sont moins descriptifs et plus Ã©ditoriaux. | Bouchard (2026) ; BlueMagnet (2026)

**Annonces de plan et signposting mÃ©tatextuel (IA)** â†’ L'Ã©criture humaine **rÃ©duit le signposting au minimum** dans les genres informels et l'accompagne de **marqueurs interactionnels** (hedges, engagement du lecteur) dans les genres formels. Un humain Ã©crit Â« I'll walk you through three things that surprised me Â» plutÃ´t que Â« In this article, we will first examineâ€¦ then discussâ€¦ and finally concludeâ€¦ Â». | Jiang & Hyland (ESP 2025)

---

## Section 4 â€” Techniques de cassure de symÃ©trie

### Le pass structurel de Bouchard

**Origine.** Louis-FranÃ§ois Bouchard (co-fondateur de Towards AI, crÃ©ateur Â« What's AI Â») a publiÃ© le 15 janvier 2026 un article intitulÃ© *How to Clean Up AI-Generated Drafts Without Sounding Like ChatGPT*, dÃ©crivant cette heuristique sous le nom Â« Do a structural pass before a language pass Â». La technique s'appuie sur deux annÃ©es d'Ã©dition de milliers de soumissions assistÃ©es par IA chez Towards AI.

**MÃ©thode.** RÃ©sumer chaque paragraphe en une seule phrase, puis lire ces rÃ©sumÃ©s comme un outline. Si la sÃ©quence suit Â« dÃ©finition â†’ liste â†’ rÃ©capitulation â†’ futur vague Â», ou si les rÃ©sumÃ©s sont structurellement interchangeables (on pourrait permuter les paragraphes sans perdre de sens), le texte est templated. Bouchard : Â« The language has been de-delved, but the thought structure is still pure model. Â»

**Quand l'appliquer.** Sur tout texte de plus de 4-5 paragraphes, comme premier filtre structurel avant toute analyse lexicale ou stylistique. L'heuristique est particuliÃ¨rement discriminante pour les essais d'opinion et articles de blog, oÃ¹ la rÃ©gularitÃ© structurelle est suspecte. Elle est moins pertinente pour les tutoriels step-by-step et la documentation, dont la rÃ©gularitÃ© est une convention de genre.

**Tentative de formalisation.** Aucune publication acadÃ©mique ne formalise directement la Â« substituabilitÃ© structurelle des paragraphes Â» comme mÃ©trique. Cependant, plusieurs travaux convergent :

- **Kim et al. (ACL 2024)** proposent un score MF-IDF (Motif Frequency-Inverse Document Frequency) extrait d'arbres RST hiÃ©rarchiques, montrant que les textes humains ont une variabilitÃ© structurelle significativement plus grande dans leurs motifs discursifs â€” ce que le test de Bouchard dÃ©tecte intuitivement.
- **Tulchinskii et al. (NeurIPS 2023)** mesurent la dimensionalitÃ© intrinsÃ¨que des embeddings : le texte IA occupe un sous-espace ~1.5 dimensions infÃ©rieur au texte humain, suggÃ©rant une uniformitÃ© structurelle quantifiable.
- **Formalisation proposÃ©e** [InfÃ©rence, non validÃ©e] : calculer la similaritÃ© cosinus entre les embeddings des rÃ©sumÃ©s mono-phrase de N paragraphes consÃ©cutifs. Si la moyenne dÃ©passe un seuil (~0.85, Ã  calibrer empiriquement), le texte est probablement templated.

**Niveau de confiance :** Ã‰levÃ© pour la technique elle-mÃªme (observation systÃ©matique de praticien). Moyen pour la formalisation proposÃ©e (infÃ©rence non testÃ©e).

### Autres heuristiques de dÃ©tection structurelle

Au-delÃ  du pass de Bouchard, 25 heuristiques praticien ont Ã©tÃ© identifiÃ©es, regroupÃ©es par catÃ©gorie :

**Tests de structure (fiabilitÃ© expert-recommandÃ©e)**

- **Test du template** (Pangram Labs / Max Spero) : vÃ©rifier si le texte suit intro â†’ 3-4 paragraphes â†’ liste Ã  puces â†’ conclusion.
- **Test d'uniformitÃ© des paragraphes** (Pangram Labs / Bradley Emi) : vÃ©rifier que les paragraphes sont de longueur approximativement Ã©gale. CorroborÃ© multi-sources.
- **Test des transitions formulaÃ¯ques** (Steere, U. North Georgia) : surreprÃ©sentation de Â« Firstly Â», Â« Furthermore Â», Â« Moreover Â», Â« On the other hand Â». BasÃ© sur 50+ essais.
- **Test des cinq structures de phrases** (Michelle Kassorla) : cinq patterns syntaxiques rÃ©currents (simple+simple, jointures par point-virgule, transitions adverbiales, modificateurs en fin de phrase, structures parallÃ¨les).
- **Test de la conclusion** (Steere + Pangram) : conclusion commenÃ§ant par Â« Overall Â» / Â« In Conclusion Â», anormalement longue, rÃ©pÃ©tant le contenu.

**Tests de contenu (fiabilitÃ© semi-empirique Ã  empirique)**

- **Test de profondeur/spÃ©cificitÃ©** (Steere, Pangram, Marian University) : absence d'insights originaux, d'anecdotes personnelles, d'observations uniques. CorroborÃ© par Â« Writing with a Reader in Mind Â» (Iperstoria 2025).
- **Test de vÃ©rification des citations** (Steere) : vÃ©rifier l'existence rÃ©elle des sources citÃ©es. **Le test le plus fiable** de cette catÃ©gorie.
- **Test de voix personnelle** (Steere, Marian U.) : absence du Â« je Â» et du hedging. ConfirmÃ© par Jiang & Hyland (ESP 2025).
- **Test du biais de subtopic** (Spero, Pangram) : sur un sujet large, l'IA gravite vers les sous-thÃ¨mes les plus Ã©vidents. Anecdotique.

**Tests de style et lexique (fiabilitÃ© variable)**

- **AI tells lexicaux** (Pangram / Spero + Emi ; Stockton) : Â« delve Â», Â« tapestry Â», Â« vibrant Â», Â« realm Â», Â« embark Â», Â« navigate Â», Â« landscape Â», Â« testament Â», Â« underscore Â», Â« foster Â». Augmentation ~400% de Â« delve Â» dans PubMed post-2022.
- **Test du Â« consensus middle Â»** (Stockton) : l'IA choisit le mot Ã  haute probabilitÃ© (Â« transform Â») plutÃ´t que le mot prÃ©cis (Â« upended Â», Â« restructured Â»).
- **Test de l'hyperbole** (Steere) : qualificatifs disproportionnÃ©s pour des sujets banals (Â« groundbreaking Â», Â« vital Â»).
- **Test de la surexplication appositionnelle** (Steere) : l'IA dÃ©finit systÃ©matiquement les personnes par des appositions (Â« Margaret Fuller, a pioneering feminist and transcendentalist thinker Â»).

**Tests de processus (fiabilitÃ© Ã©levÃ©e)**

- **DÃ©fense orale** (Kelley, Inside Higher Ed 2023 ; Hammer et Elliott, U. Penn) : demander Ã  l'auteur de discuter et dÃ©fendre son texte. Test le plus fiable en contexte Ã©ducatif.
- **Comparaison avec un baseline IA** (Kelley, Pangram) : gÃ©nÃ©rer le mÃªme exercice avec ChatGPT et comparer.

**Avertissement critique :** Plusieurs Â« tells IA Â» correspondent Ã  des conventions normales de l'Ã©criture acadÃ©mique APA (voix passive, transitions formelles), crÃ©ant un risque de faux positif significatif pour certaines disciplines (lettre de rÃ©ponse Ã  Steere, _Inside Higher Ed_, aoÃ»t 2024).

### Techniques validÃ©es empiriquement ou fondÃ©es sur la recherche

**RÃ©Ã©crire la structure, pas le vocabulaire.** Consensus de multiples sources indÃ©pendantes : les dÃ©tecteurs rÃ©agissent plus aux patterns de phrases prÃ©visibles qu'au vocabulaire. Changer l'ordre des phrases, varier les ouvertures, modifier le rythme est plus efficace que remplacer des synonymes. AISEO confirme : Â« Editing manually often fails because writers focus on word changes instead of structural variation. Â» JustDone corrobore : Â« AI detectors react more to predictable sentence patterns than vocabulary. Â» _Niveau de confiance : Ã‰levÃ© â€” convergence de sources indÃ©pendantes._

**Varier dÃ©libÃ©rÃ©ment la longueur des phrases.** Alterner une phrase longue explicative (25+ mots), une phrase courte percutante (5 mots), puis une phrase de longueur moyenne. Cette technique cible directement la mÃ©trique de burstiness mesurÃ©e par GPTZero et QuillBot. Exemple concret : au lieu de trois phrases de 15 mots, Ã©crire une phrase de 25 mots, puis Â« C'est tout. Â», puis une phrase de 12 mots. | JustDone (2025) ; NetusAI _Niveau de confiance : Ã‰levÃ© â€” directement liÃ© Ã  la mÃ©trique de burstiness documentÃ©e._

**Varier la longueur des paragraphes.** Faire coexister des paragraphes de 2 phrases (pour l'emphase) et des paragraphes de 6-7 phrases (pour les preuves dÃ©taillÃ©es). Briser l'apparence Â« machine-balanced Â» de paragraphes de longueur identique. | Pangram Labs (2025) ; JustDone _Niveau de confiance : Moyen â€” observation de praticiens, cohÃ©rent avec la recherche sur la burstiness._

**Utiliser un Â« information pattern Â» intentionnel.** Choisir dÃ©libÃ©rÃ©ment un arc narratif (problÃ¨me â†’ investigation â†’ rÃ©vÃ©lation ; question â†’ exploration â†’ complication â†’ insight) au lieu de laisser l'IA imposer son template par dÃ©faut. Tom Johnson dÃ©taille cette approche : Â« My first step is to identify the information pattern I want to use. This narrative arc â€” from raising a concern, to chronicling its study, to achieving revelation â€” mimics the hero's journey story structure. Â» | Tom Johnson, idratherbewriting.com (oct. 2023) _Niveau de confiance : Moyen â€” recommandation d'un praticien expert en rÃ©daction technique, non validÃ©e empiriquement._

**Appliquer le framework de Christensen (rhÃ©torique gÃ©nÃ©rative de la phrase).** Le pattern de phrase cumulative de Francis Christensen â€” une proposition de base suivie d'une sÃ©rie de modificateurs libres â€” fournit un cadre pour crÃ©er des structures phrastiques Ã  la fois complexes et organiquement variables, brisant la monotonie syntaxique de l'IA. | Daniel Plate, thÃ¨se de master, Lindenwood University (2025) _Niveau de confiance : Faible â€” source unique (thÃ¨se de master), mais fondement thÃ©orique solide (Christensen est une rÃ©fÃ©rence en rhÃ©torique)._

### Techniques recommandÃ©es par des praticiens

**Ã‰laguer les reformulations (Â« Delete-to-Reveal Â»).** Lire chaque paragraphe et supprimer 1-2 phrases qui ne font que reformuler l'idÃ©e dÃ©jÃ  Ã©noncÃ©e. L'IA gonfle les paragraphes par reformulation ; l'Ã©criture humaine est plus tendue. ComplÃ©mentaire Ã  la technique Bouchard (rÃ©sumÃ© en une phrase pour rÃ©vÃ©ler le template), cette technique brise le template en le raccourcissant. | JustDone (2025) _Niveau de confiance : Moyen._

**Alterner voix personnelle et explication analytique.** InsÃ©rer des anecdotes en premiÃ¨re personne (Â« J'ai testÃ© ceci et voilÃ  ce qui s'est passÃ© Â») entre les passages explicatifs en troisiÃ¨me personne. Tom Johnson dÃ©crit cette technique comme l'une des plus efficaces : Â« when you switch into the 'I' mode, narrating a personal experience to complement explanations, it helps readers believe that all the content is human-generated. Â» | Tom Johnson, idratherbewriting.com (oct. 2023) _Niveau de confiance : Moyen â€” praticien expÃ©rimentÃ©, mais pas de validation quantitative._

**Casser les triplets en structures asymÃ©triques.** Quand l'IA organise les points en groupes de trois, fusionner deux points en une phrase ou dÃ©velopper un seul point en un exemple dÃ©taillÃ©, brisant la symÃ©trie structurelle. | JustDone (2025) _Niveau de confiance : Moyen._

**Diversifier les ouvertures de phrase.** Cesser de commencer plusieurs phrases par Â« This Â» ou Â« The Â». Varier : connecteurs, exemples spÃ©cifiques, assertions directes, questions, fragments. | JustDone (2025) _Niveau de confiance : Moyen._

**Ajouter une entrÃ©e graduelle (warm-up narratif).** Au lieu de l'approche IA Â« droit au but Â», insÃ©rer un contexte anecdotique ou une question avant d'arriver Ã  la thÃ¨se. | Steere, _Inside Higher Ed_ (2024) _Niveau de confiance : Ã‰levÃ© â€” fondÃ© sur comparaison systÃ©matique humain/IA._

**Lire Ã  voix haute pour dÃ©tecter l'absence de Â« musique du texte Â».** Technique recommandÃ©e spÃ©cifiquement pour le franÃ§ais par StÃ©phane Torregrosa : la lecture orale rÃ©vÃ¨le l'uniformitÃ© rythmique que l'Å“il ne perÃ§oit pas Ã  l'Ã©crit. | Squid-Impact (sept. 2025) _Niveau de confiance : Faible â€” praticien unique, non validÃ©._

**Utiliser les dÃ©tecteurs IA comme outil diagnostic (feedback loop structurel).** Soumettre le texte Ã  un dÃ©tecteur, identifier les zones Ã  burstiness faible ou dÃ©tectÃ©es comme IA, puis varier manuellement ces passages â€” non pour Â« battre Â» le dÃ©tecteur, mais pour localiser l'uniformitÃ© structurelle. | NetusAI _Niveau de confiance : Moyen._

---

## Section 5 â€” Variations par modÃ¨le et par genre

### Empreintes stylistiques distinctes par famille de LLM

La recherche rÃ©cente confirme sans ambiguÃ¯tÃ© que **chaque famille de LLM possÃ¨de une empreinte stylistique identifiable**. McGovern et al. (COLING 2025, arXiv 2405.14057) dÃ©montrent que des classificateurs simples basÃ©s sur des n-grams et des POS features atteignent des performances robustes pour identifier le modÃ¨le source d'un texte, mÃªme hors domaine. Les empreintes sont Â« gÃ©nÃ©tiques Â» â€” elles persistent entre les variantes d'une mÃªme famille (llama-13b et llama-65b ont des empreintes similaires). ChatGPT et davinci (mÃªme famille OpenAI) partagent des empreintes proches, tandis que Flan diverge substantiellement.

Bitton, Bitton et Nisan (Copyleaks, arXiv 2503.01659, mars 2025) confirment ces rÃ©sultats avec un ensemble de 3 classificateurs entraÃ®nÃ©s sur Claude, Gemini, Llama et OpenAI, atteignant une **prÃ©cision de 0.9988 et un taux de faux positifs de 0.0004** sur 200 000 Ã©chantillons. RÃ©sultat notable : les empreintes persistent Â« even when prompted to write in different writing styles Â». Un test sur des modÃ¨les non vus rÃ©vÃ¨le que **DeepSeek-R1 est classifiÃ© comme OpenAI dans 74.2% des cas** â€” suggÃ©rant fortement un entraÃ®nement par distillation sur des sorties OpenAI. Phi-4 et Grok-1, en revanche, montrent des empreintes totalement distinctes.

Cependant, MuÃ±oz-Ortiz et al. (2024) soulignent que les **diffÃ©rences entre LLM et humains sont systÃ©matiquement plus grandes que les diffÃ©rences entre LLM eux-mÃªmes** â€” les modÃ¨les se ressemblent plus entre eux qu'ils ne ressemblent aux humains. Reinhart et al. (PNAS 2025) ajoutent que l'**instruction tuning amplifie la divergence stylistique** par rapport aux humains : les modÃ¨les de base Llama 3 ressemblent davantage aux humains que leurs versions instruction-tuned, et le scaling (augmentation de taille) ne corrige pas ce problÃ¨me structurel.

### Variations par genre textuel et calibration des signaux

La recherche sur les variations structurelles selon le genre est insuffisamment dÃ©veloppÃ©e mais livre des constats opÃ©rationnellement importants. L'Ã©tude Springer 2026 (*Evaluating accuracy of AI content detectors*, Int. J. Educational Integrity) testant Turnitin et Originality sur 192 textes montre un effondrement de prÃ©cision du domaine humanities au domaine scientifique : Turnitin passe de 0.86 Ã  0.51, Originality de 0.96 Ã  0.58. Le benchmark RAID (Dugan et al., ACL 2024) confirme sur 6+ millions de gÃ©nÃ©rations que le taux de faux positifs varie fortement par domaine lorsqu'un seuil unique est utilisÃ©.

Sardinha (2024, citÃ© dans TerÃ§on, arXiv 2510.05136) offre la comparaison la plus systÃ©matique : les textes acadÃ©miques IA manquent d'Ã©lÃ©ments narratifs et de rÃ©fÃ©rences explicites ; les essais IA sont informationnellement denses mais moins impliquÃ©s ; les articles de presse IA montrent moins d'implication et de narration ; les conversations IA sont plus abstraites. Le constat-clÃ© : Â« les diffÃ©rences de degrÃ© d'abstraction ne deviennent apparentes que lorsqu'on prend en compte le genre textuel. Â»

Tom Johnson (idratherbewriting.com, oct. 2023) observe que l'IA Â« inevitably steers into explanation more than argument Â» â€” elle dÃ©faille vers le mode expositif quel que soit le genre, alors que les billets de blog et essais personnels requiÃ¨rent des structures argumentatives, exploratoires ou narratives.

#### Calibration par genre : recommandations opÃ©rationnelles

**Tutoriel technique : supprimer 5 signaux sur 16.** La rÃ©gularitÃ© structurelle est inhÃ©rente au genre. Les phrases impÃ©ratives courtes, les Ã©tapes numÃ©rotÃ©es, l'entrÃ©e directe dans le sujet et l'absence de marqueurs Ã©pistÃ©miques sont des conventions. Signaux Ã  supprimer : #1 (longueur de phrase), #8 (structure list-like), #10 (entrÃ©e directe), #13 (marqueurs Ã©pistÃ©miques), #14 (burstiness). Signaux qui restent pertinents : la perte de cohÃ©rence entre Ã©tapes dÃ©pendantes (#3) est le signal le plus fiable â€” un humain maintient les dÃ©pendances logiques, l'IA perd le fil. L'absence de variation de registre (#4) est discriminante : les tutoriels humains injectent de la personnalitÃ©. La complexitÃ© syntaxique excessive (#5) est un signal fort car les tutoriels doivent Ãªtre simples.

**Essai d'opinion / blog : activer tous les signaux Ã  sensibilitÃ© maximale.** Aucun des 16 signaux ne prÃ©sente de risque de faux positif significatif. Les signaux les plus discriminants sont la basse burstiness (#14), l'absence de marqueurs Ã©pistÃ©miques (#13), le manque de variation de registre (#4) et la persistance de la 3e personne (#11). C'est le meilleur genre pour la dÃ©tection structurelle.

**Article technique / Ã©tat de l'art : supprimer la 3e personne, relever les seuils.** L'Ã©criture acadÃ©mique utilise conventionnellement la 3e personne (#11 â€” supprimer). L'entrÃ©e directe (#10) est normale. Les marqueurs Ã©pistÃ©miques (#13) et la burstiness (#14) doivent voir leur seuil relevÃ©. Le signal le plus fiable : les ouvertures formulaÃ¯ques (#7) â€” Â« In recent years, X has gained significant attention Â» est devenu quasi-diagnostique. L'Ã©tude Sci-SpanDet (arXiv 2510.00890) montre que le conditionnement par section amÃ©liore la dÃ©tection dans le texte acadÃ©mique.

**Documentation logicielle : 10-12 signaux sur 16 Ã  supprimer.** Pire genre pour la dÃ©tection structurelle. Pangram Labs rapporte un taux de faux positifs de 0.0% et recommande de ne pas scanner les manuels d'instruction. Seuls trois signaux restent partiellement fiables : la cohÃ©rence interne (#3), la complexitÃ© syntaxique excessive (#5), l'usage du em dash (#12). Approches alternatives plus efficaces : vÃ©rification de l'exactitude factuelle, validation des rÃ©fÃ©rences croisÃ©es, correction du code.

**Newsletter technique : profil hybride.** La mixitÃ© rÃ©sumÃ©s/commentaire/recommandations crÃ©e une burstiness Ã©levÃ©e attendue, rendant l'uniformitÃ© IA trÃ¨s suspecte. Signaux partiellement supprimables : #10 (entrÃ©e directe) et #8 (listes dans les sections roundup). Tous les autres restent actifs. [INCERTAIN â€” pas d'Ã©tude empirique directe sur les newsletters.]

#### Le problÃ¨me du code dans le texte technique

Les blocs de code perturbent toutes les mÃ©triques structurelles : ils crÃ©ent une distribution bimodale artificielle de longueurs et introduisent une perplexitÃ© extrÃªme masquant la basse perplexitÃ© de la prose IA. Pangram Labs rapporte ~20% de faux nÃ©gatifs sur le code IA seul. **Recommandation : isoler les blocs de code avant l'analyse de la prose.** Analyser les segments de prose indÃ©pendamment. Les segments courts entre blocs de code peuvent Ãªtre trop brefs pour une dÃ©tection fiable (Pangram recommande Â« over a couple hundred words Â»).

#### Matrice genre Ã— signal

| Signal | Tutoriel | Blog / Opinion | Article technique | Doc logicielle | Newsletter |
|--------|----------|---------------|-------------------|----------------|------------|
| #1 Longueur de phrase Ã©troite | âŒ | âœ… Ã‰levÃ© | âš ï¸ Relever seuil | âŒ | âœ… Moyen-Ã©levÃ© |
| #2 Ã‰laboration RST | âœ… Moyen-Ã©levÃ© | âœ… Ã‰levÃ© | âœ… Ã‰levÃ© | âœ… Moyen | âœ… Ã‰levÃ© |
| #3 Perte de cohÃ©rence | âœ… Ã‰levÃ© | âœ… Moyen | âœ… Ã‰levÃ© | âœ… Moyen-Ã©levÃ© | âœ… Moyen |
| #4 Absence variation registre | âœ… Moyen-Ã©levÃ© | âœ… TrÃ¨s Ã©levÃ© | âœ… Moyen-Ã©levÃ© | âŒ | âœ… TrÃ¨s Ã©levÃ© |
| #5 ComplexitÃ© syntaxique | âœ… Ã‰levÃ© | âœ… Moyen | âœ… Ã‰levÃ© | âœ… Ã‰levÃ© | âœ… Moyen-Ã©levÃ© |
| #6 Template tripartite | âš ï¸ Moyen | âœ… Ã‰levÃ© | âœ… Ã‰levÃ© | âŒ | âœ… Moyen-Ã©levÃ© |
| #7 Ouvertures formulaÃ¯ques | âš ï¸ Moyen | âœ… Ã‰levÃ© | âœ… TrÃ¨s Ã©levÃ© | âŒ | âœ… Ã‰levÃ© |
| #8 Structure list-like | âŒ | âœ… Moyen-Ã©levÃ© | âœ… Moyen | âŒ | âš ï¸ Moyen |
| #9 Conclusions rÃ©pÃ©titives | âœ… Moyen | âœ… Ã‰levÃ© | âœ… Ã‰levÃ© | âŒ | âœ… Moyen-Ã©levÃ© |
| #10 EntrÃ©e directe | âŒ | âœ… Moyen | âŒ | âŒ | âš ï¸ Moyen |
| #11 Persistance 3e personne | âœ… Moyen | âœ… Ã‰levÃ© | âŒ | âŒ | âœ… Ã‰levÃ© |
| #12 Em dash excessif | âœ… Ã‰levÃ© | âœ… Moyen-Ã©levÃ© | âœ… Ã‰levÃ© | âœ… Moyen-Ã©levÃ© | âœ… Moyen |
| #13 Marqueurs Ã©pistÃ©miques | âŒ | âœ… TrÃ¨s Ã©levÃ© | âš ï¸ Relever seuil | âŒ | âœ… Ã‰levÃ© |
| #14 Basse burstiness | âŒ | âœ… TrÃ¨s Ã©levÃ© | âš ï¸ Relever seuil | âŒ | âœ… TrÃ¨s Ã©levÃ© |
| #15 Sous-titres gÃ©nÃ©riques | âš ï¸ Moyen | âœ… Ã‰levÃ© | âœ… TrÃ¨s Ã©levÃ© | âŒ | âœ… Ã‰levÃ© |
| #16 Annonce de plan | âš ï¸ Moyen | âœ… Ã‰levÃ© | âš ï¸ Moyen | âŒ | âœ… Ã‰levÃ© |

**LÃ©gende :** âœ… = signal pertinent (poids plein), âš ï¸ = signal Ã  pondÃ©rer (poids rÃ©duit), âŒ = signal Ã  supprimer (faux positif probable)

**Signaux universels** (fiables dans tous les genres) : #3 (cohÃ©rence), #5 (complexitÃ© syntaxique), #12 (em dash).
**Signaux les plus genre-dÃ©pendants** : #1, #8, #10, #13, #14 â€” variant de Â« supprimer Â» Ã  Â« trÃ¨s Ã©levÃ© Â».
**Meilleur genre pour la dÃ©tection** : blog/opinion (tous signaux actifs).
**Pire genre** : documentation logicielle (10-12 signaux sur 16 Ã  supprimer).
## Section 6 â€” Burstiness et variabilitÃ© phrastique

### Ã‰tat actuel des connaissances

La burstiness â€” variabilitÃ© de la complexitÃ© et de la longueur phrastique au sein d'un document â€” est le **signal structurel le plus citÃ©** dans l'Ã©cosystÃ¨me de dÃ©tection IA, mais sa fiabilitÃ© comme prÃ©dicteur isolÃ© est **sÃ©rieusement remise en question** par la recherche rÃ©cente.

Le concept a Ã©tÃ© popularisÃ© par Edward Tian (GPTZero, janvier 2023) qui l'a dÃ©fini comme Â« a measure of how much writing patterns and text perplexities vary over the entire document Â». L'implÃ©mentation initiale de GPTZero Ã©tait remarquablement simple : la burstiness Ã©quivalait au **maximum de la perplexitÃ© par phrase** (non une mesure de variance, comme souvent dÃ©crit). Le modÃ¨le de production actuel est plus sophistiquÃ©, intÃ©grant la burstiness comme l'un de sept composants.

Le signal de base est rÃ©el : **les textes LLM montrent effectivement une burstiness plus faible** que les textes humains, confirmÃ© par MuÃ±oz-Ortiz et al. (2024) avec des donnÃ©es quantitatives sur 6 modÃ¨les, et par Kujur (SSRN, 2025) qui documente Â« more uniform sentence structures Â» dans le texte IA. Les humains alternent naturellement entre phrases courtes et percutantes et phrases longues et Ã©laborÃ©es, crÃ©ant une variation rythmique que les LLM ne reproduisent pas spontanÃ©ment.

### Limites critiques documentÃ©es

Trois problÃ¨mes majeurs limitent la fiabilitÃ© de la burstiness comme signal de dÃ©tection.

Le **biais contre les locuteurs non natifs** est le plus grave. Liang et al. (Stanford, _Patterns_ 4(7), 2023) ont dÃ©montrÃ© que plus de **61% des essais TOEFL rÃ©digÃ©s par des locuteurs non natifs** sont faussement classifiÃ©s comme IA par les dÃ©tecteurs basÃ©s sur la perplexitÃ©/burstiness, contre seulement ~5% pour les locuteurs natifs. Les Ã©crivains non natifs produisent naturellement un texte Ã  variance syntaxique rÃ©duite (burstiness basse), structurellement indistinguable du texte IA par cette mÃ©trique.

Le **problÃ¨me de contamination des donnÃ©es d'entraÃ®nement** est soulevÃ© par Pangram Labs (Bradley Emi, mars 2025) : tout texte prÃ©sent dans les donnÃ©es d'entraÃ®nement du LLM utilisÃ© pour calculer la perplexitÃ© aura une perplexitÃ© uniformÃ©ment basse, donc une burstiness basse, et sera faussement classifiÃ© comme IA. Pangram Labs dÃ©montre que la DÃ©claration d'IndÃ©pendance amÃ©ricaine, des passages bibliques, et des articles Wikipedia sont systÃ©matiquement flaggÃ©s comme IA.

L'**amÃ©lioration des LLM** Ã©rode progressivement le signal. Kujur (2025) note explicitement : Â« as language models have advanced, these differences have diminished significantly. Â» GPT-4 et les modÃ¨les ultÃ©rieurs montrent une capacitÃ© accrue Ã  mimer la variabilitÃ© humaine. Plusieurs sources mentionnent que les modÃ¨les 2025 peuvent Â« incorporate variability algorithms Â» [INCERTAIN â€” aucune source acadÃ©mique ne confirme un mÃ©canisme spÃ©cifique].

### Mesure concrÃ¨te

Pour mesurer la burstiness d'un texte en pratique, la mÃ©thode la plus accessible est le **coefficient de variation de la longueur de phrase** (CV = Ã©cart-type / moyenne des longueurs de phrase en tokens). Un CV faible suggÃ¨re une uniformitÃ© structurelle. L'approche plus sophistiquÃ©e calcule la perplexitÃ© par phrase via un modÃ¨le de langue (GPT-2 ou similaire) puis mesure la variance de ces scores. Les outils commerciaux (GPTZero, QuillBot) automatisent ce calcul mais ne divulguent pas leurs seuils exacts.

Turnitin a pris une position notable en dÃ©clarant explicitement dans son livre blanc (aoÃ»t 2024) que la perplexitÃ© et la burstiness sont **insuffisantes** et que leur architecture transformeur profond capture Â« an enormous number of long-range statistical dependencies Â» plus informatives que ces mÃ©triques simples.

### Verdict

La burstiness est un **signal rÃ©el mais non suffisant**. Elle est utile comme composant d'un ensemble de signaux, mais **jamais fiable isolÃ©ment**. Son utilisation pour la dÃ©tection dans un contexte bilingue FR/EN est particuliÃ¨rement risquÃ©e Ã©tant donnÃ© le biais documentÃ© contre les Ã©critures non natives. Pour un workflow d'Ã©criture humain-IA, la burstiness est plus utile comme **outil diagnostic** (identifier les passages trop uniformes Ã  rÃ©viser) que comme mÃ©trique de validation finale.

**Niveau de confiance global : Ã‰levÃ©** pour l'existence du signal ; **Ã‰levÃ©** pour ses limitations.

---

## Section 7 â€” Lacunes et questions ouvertes

### Lacunes majeures identifiÃ©es

**Absence quasi totale de recherche francophone sur les patterns structurels.** Aucune Ã©tude acadÃ©mique franÃ§aise ne traite spÃ©cifiquement des signatures structurelles (longueur de paragraphe, distribution phrastique, schÃ©mas organisationnels) du texte IA en franÃ§ais. Le papier le plus proche est MOSAIC (Dubois, Piantanida, Yvon â€” Sorbonne/ISIR, ACL 2025), mais il se concentre sur les approches perplexitÃ©/compression et non sur la structure discursive. Les observations structurelles sur le franÃ§ais proviennent exclusivement de praticiens (Torregrosa, Compilatio, Kitcreanet) sans validation empirique formelle. C'est une lacune significative pour un blog technique bilingue.

**Pas d'Ã©tude longitudinale systÃ©matique.** Aucune Ã©tude n'a suivi les mÃªmes mÃ©triques structurelles Ã  travers les gÃ©nÃ©rations de modÃ¨les (GPT-3 â†’ 3.5 â†’ 4 â†’ 4o) avec une mÃ©thodologie contrÃ´lÃ©e. Le rÃ©cit d'Â« Ã©volution Â» est infÃ©rÃ© de comparaisons transversales, non de mesures longitudinales.

**Genres techniques sous-Ã©tudiÃ©s.** Les tutoriels, la documentation technique, et les articles de blog technique â€” exactement les genres pertinents pour le contexte de cette recherche â€” sont **quasi absents de la littÃ©rature empirique**. La majoritÃ© des Ã©tudes portent sur les essais acadÃ©miques et les articles de presse. L'extrapolation des rÃ©sultats Ã  d'autres genres est incertaine.

**Le pattern Â« dÃ©finition â†’ explication â†’ nuance â†’ rÃ©sumÃ© Â» est dÃ©sormais partiellement documentÃ©.** Bouchard (2026) dÃ©crit un Ã©quivalent (Â« definition â†’ list â†’ recap â†’ vague future Â») et Jiang & Hyland (ESP 2025) formalisent la surreprÃ©sentation des frame markers comme composante mesurable. Le pattern n'a pas de nom formel unique dans la littÃ©rature, mais il est dÃ©sormais corroborÃ© par des sources multiples (praticiens et acadÃ©miques).

**Pas de comparaison structurelle formelle Claude vs GPT vs Gemini.** Les Ã©tudes de fingerprinting (McGovern et al., Bitton et al.) confirment que les modÃ¨les ont des empreintes distinctes, mais les descriptions qualitatives des diffÃ©rences structurelles spÃ©cifiques entre Claude, GPT-4 et Gemini restent **anecdotiques et souvent issues de contenus marketing**. La seule donnÃ©e structurellement informative est que les empreintes sont Â« familiales Â» et persistent malgrÃ© le prompting stylistique.

### Contradictions entre sources

**Burstiness : signal fiable ou obsolÃ¨te ?** GPTZero le prÃ©sente comme Â« key factor unique to GPTZero detector Â» ; Pangram Labs le qualifie de fondamentalement insuffisant ; Turnitin le considÃ¨re explicitement inadÃ©quat seul. La vÃ©ritÃ© est probablement contextuelle : utile pour les textes longs et les modÃ¨les plus anciens, dÃ©clinant en fiabilitÃ© avec les modÃ¨les rÃ©cents.

**L'instruction tuning : amÃ©liore ou dÃ©grade la dÃ©tectabilitÃ© ?** Kirk et al. (ICLR 2024) montrent que le RLHF **rÃ©duit la diversitÃ©** de sortie (devrait faciliter la dÃ©tection), mais Reinhart et al. (PNAS 2025) montrent que les modÃ¨les instruction-tuned **divergent davantage des humains** stylistiquement. Ces deux constats sont compatibles (moins divers ET plus Ã©loignÃ©s des humains), mais leur implication pour la dÃ©tection effective est ambiguÃ«.

**RÃ©sultat d'impossibilitÃ© vs dÃ©tection pratique.** Sadasivan et al. (ICLR 2024) prouvent thÃ©oriquement qu'un LLM suffisamment bon rend la dÃ©tection marginalement meilleure qu'alÃ©atoire. Or les dÃ©tecteurs actuels fonctionnent avec une prÃ©cision substantielle (>80% dans beaucoup de conditions). La rÃ©conciliation est que les modÃ¨les actuels ne sont pas encore Â« suffisamment bons Â» au sens du thÃ©orÃ¨me, et que les approches structurelles (discours RST, features de Biber) semblent plus robustes au paraphrasing que les approches token-level â€” mais cette robustesse n'est pas garantie Ã  long terme.

### Questions ouvertes pour la recherche future

La question de savoir si les patterns structurels IA en **franÃ§ais** diffÃ¨rent de ceux en anglais reste entiÃ¨rement ouverte. Compilatio rapporte des taux de dÃ©tection Ã©levÃ©s (98.5%) sur le franÃ§ais aprÃ¨s fine-tuning spÃ©cifique, mais ces chiffres sont auto-reportÃ©s et non vÃ©rifiÃ©s indÃ©pendamment. L'oscillation entre Â« traduction littÃ©rale et adaptation culturelle Â» mentionnÃ©e par Torregrosa pourrait constituer un signal structurel spÃ©cifique au franÃ§ais, mais cette hypothÃ¨se n'a Ã©tÃ© ni testÃ©e ni quantifiÃ©e.

L'impact de la **tempÃ©rature de gÃ©nÃ©ration et du system prompt** sur les patterns structurels est un angle mort majeur. Les Ã©tudes comparent typiquement la sortie Â« par dÃ©faut Â» des modÃ¨les. Or un system prompt soigneusement conÃ§u (comme ceux utilisÃ©s dans un workflow en 7 phases) pourrait attÃ©nuer significativement les patterns structurels documentÃ©s â€” sans que cette attÃ©nuation ait Ã©tÃ© mesurÃ©e.

Enfin, l'**homogÃ©nÃ©isation linguistique Ã  grande Ã©chelle** documentÃ©e par Sourati et al. (2025) â€” diminution de la variabilitÃ© stylistique sur Reddit, dans l'Ã©criture scientifique et les revues peer-reviewed â€” pose une question fondamentale : si l'Ã©criture humaine elle-mÃªme converge vers les patterns LLM par exposition et usage, la distinction structurelle humain/IA pourrait devenir intrinsÃ¨quement plus difficile, indÃ©pendamment des progrÃ¨s des dÃ©tecteurs. Cette hypothÃ¨se n'est pas encore testÃ©e empiriquement mais constitue sans doute la question la plus importante pour les annÃ©es Ã  venir.

La question de la **calibration optimale des seuils par genre** reste ouverte. FairOPT (arXiv 2502.04528) propose des seuils adaptatifs rÃ©duisant la disparitÃ© de 27.4% avec moins de 0.1% de perte de prÃ©cision, mais cette approche n'a pas Ã©tÃ© testÃ©e avec la matrice de signaux structurels proposÃ©e ici. Les taux de faux positifs par domaine publiÃ©s par Pangram Labs (0.0% pour la documentation de code, 0.23% pour les recettes) suggÃ¨rent que la calibration par genre est le levier le plus important pour la fiabilitÃ© opÃ©rationnelle.

## Section 8 â€” Workflow de dÃ©tection recommandÃ©

La sÃ©quence ci-dessous ordonne les vÃ©rifications du plus fiable au moins fiable, en intÃ©grant la calibration par genre comme prÃ©requis.

### Ã‰tape 0 â€” Classification du genre

Avant toute analyse, identifier le genre textuel (tutoriel, blog, article technique, documentation, newsletter) et charger le profil de calibration correspondant (matrice Section 5). Si le texte contient des blocs de code, les isoler et analyser la prose seule.

### Ã‰tape 1 â€” Pass structurel de Bouchard (confiance : Ã©levÃ©e)

RÃ©sumer chaque paragraphe en une phrase. Lire les rÃ©sumÃ©s comme un outline. Si la sÃ©quence suit Â« dÃ©finition â†’ liste â†’ rÃ©capitulation â†’ futur vague Â» ou si les rÃ©sumÃ©s sont interchangeables, c'est un signal fort. Ce test prend 2-3 minutes et offre le meilleur ratio signal/effort.

### Ã‰tape 2 â€” Signaux universels (confiance : Ã©levÃ©e)

VÃ©rifier les trois signaux fiables dans tous les genres : perte de cohÃ©rence dans les documents longs (#3), complexitÃ© syntaxique excessive (#5), surreprÃ©sentation du em dash (#12). Taux de faux positifs bas quelle que soit la catÃ©gorie textuelle.

### Ã‰tape 3 â€” Signaux calibrÃ©s par genre (confiance : Ã©levÃ©e Ã  moyenne)

Appliquer les signaux marquÃ©s âœ… dans la matrice pour le genre identifiÃ©. Pour le blog/opinion, activer tous les signaux Ã  sensibilitÃ© maximale. Pour le tutoriel, se concentrer sur la cohÃ©rence inter-Ã©tapes et la variation de registre. Pour l'article technique, surveiller prioritairement les ouvertures formulaÃ¯ques et les sous-titres gÃ©nÃ©riques.

### Ã‰tape 4 â€” Analyse lexicale ciblÃ©e (confiance : moyenne-Ã©levÃ©e)

Scanner pour les AI tells lexicaux (Â« delve Â», Â« tapestry Â», Â« vibrant Â», Â« landscape Â»), les phrases rouges (Â« It's important to note Â», Â« In the ever-evolving landscape Â»), et les noms IA (Â« Emily Â», Â« Sarah Â» dans les exemples). Signal fort en agrÃ©gat mais faible individuellement.

### Ã‰tape 5 â€” VÃ©rification du mÃ©tadiscours (confiance : moyenne-Ã©levÃ©e, sauf genre acadÃ©mique)

Mesurer le ratio mÃ©tadiscours interactif (signposting, transitions, frame markers) vs mÃ©tadiscours interactionnel (hedges, boosters, marqueurs d'attitude). Un ratio Ã©levÃ© interactif / bas interactionnel est un signal IA. L'Ã©criture acadÃ©mique prÃ©sente naturellement un ratio Ã©levÃ© de mÃ©tadiscours interactif â€” pondÃ©rer en consÃ©quence.

### Ã‰tape 6 â€” Tests de contenu (confiance : variable)

VÃ©rifier la profondeur et la spÃ©cificitÃ© : insights non Ã©vidents, anecdotes personnelles, rÃ©fÃ©rences Ã  des expÃ©riences spÃ©cifiques. VÃ©rifier les citations si prÃ©sentes (test le plus fiable de cet axe). Ã‰valuer la voix personnelle et le biais de subtopic.

### Ã‰tape 7 â€” Jugement global pondÃ©rÃ©

Aucun signal individuel n'est dÃ©finitif. Seuil recommandÃ© [InfÃ©rence] : **3+ signaux calibrÃ©s positifs = investigation approfondie**, **5+ signaux = forte prÃ©somption**. Documenter les signaux dÃ©tectÃ©s et leur poids dans le genre concernÃ©.