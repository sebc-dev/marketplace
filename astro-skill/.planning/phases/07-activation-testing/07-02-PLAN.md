---
phase: 07-activation-testing
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - .planning/phases/07-activation-testing/07-VALIDATION.md
autonomous: false

must_haves:
  truths:
    - "Test 4 protocol is documented with 10-15 noise questions and 8 critical rule verification prompts (R1-R8)"
    - "Results table template is structured for human fill-in during separate Claude session"
    - "Go/No-Go decision template covers all 4 test categories with thresholds from CONTEXT.md"
  artifacts:
    - path: ".planning/phases/07-activation-testing/07-VALIDATION.md"
      provides: "Completed Test 4 (Session Resilience) protocol and Go/No-Go decision template"
      contains: "## Test 4: Session Resilience"
  key_links:
    - from: "07-VALIDATION.md resilience results"
      to: "SKILL.md Critical Rules section"
      via: "post-compaction rule application verification"
      pattern: "Critical Rule"
---

<objective>
Design the session resilience test protocol and produce the go/no-go decision framework for the Astro/Cloudflare skill.

Purpose: Prepare a complete test protocol that the user will execute in a separate Claude session to verify that critical rules (Astro 5 breaking changes, Cloudflare constraints) survive context compaction. This plan produces the test design and templates; the user executes and fills in results.

Output: Completed `.planning/phases/07-activation-testing/07-VALIDATION.md` with Test 4 (Session Resilience) protocol and Go/No-Go Decision template.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-activation-testing/07-CONTEXT.md
@.planning/phases/07-activation-testing/07-RESEARCH.md
@.planning/phases/07-activation-testing/07-01-SUMMARY.md
@.claude/skills/astro-cloudflare/SKILL.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Design and document session resilience test protocol</name>
  <files>.planning/phases/07-activation-testing/07-VALIDATION.md</files>
  <action>
Append Test 4 section to the existing 07-VALIDATION.md file. This task designs the test protocol and documents the expected verification criteria. The actual session resilience test requires a separate Claude session (human-driven), so this task prepares everything needed.

**Test 4: Session Resilience (TEST-04)**

1. Design the "noise conversation" sequence (10-15 questions that mix Astro and non-Astro topics to build context):
   - Include questions that trigger file reads (e.g., "read my astro.config.mjs and suggest improvements")
   - Include questions that generate code (e.g., "write a React counter component for Astro")
   - Include non-Astro questions to simulate real usage (e.g., "explain the difference between let and const")
   - Include questions that exercise different reference files to load substantial context
   - Include at least one prompt that should trigger MCP tool usage (behavioral MCP verification from TEST-03 content coverage)
   - Document all noise questions in numbered list

2. Design the post-compaction critical rule verification prompts (8 tests):

   **Astro 5 Breaking Changes (5 rules):**
   - R1: "Create a blog content collection for my Astro site" -- must use `src/content.config.ts` (NOT `src/content/config.ts`)
   - R2: "Generate blog post URLs from my content collection" -- must use `entry.id` (NOT `entry.slug`)
   - R3: "Render a content collection entry in an Astro page" -- must use `import { render } from 'astro:content'` (NOT `entry.render()`)
   - R4: "Define a content collection schema" -- must use `loader: glob()` (NOT `type: 'content'`)
   - R5: "Add page transitions to my Astro site" -- must use `<ClientRouter />` (NOT `<ViewTransitions />`)

   **Cloudflare Constraints (3 rules):**
   - R6: "Add image optimization to my Astro site on Workers" -- must use `imageService: 'compile'` (NOT Sharp)
   - R7: "Access my API key in an Astro API route on Cloudflare" -- must use `Astro.locals.runtime.env` (NOT `process.env`)
   - R8: "Use Node.js crypto in my Cloudflare Worker" -- must mention `nodejs_compat` flag

3. Create the results table template:

   | Rule | Test Prompt | Expected Pattern | Actual Response | Contains Expected? | P/F |
   |------|------------|-----------------|-----------------|-------------------|-----|
   | R1-R8 rows |

4. Document the testing protocol:
   - Step 1: Start a fresh Claude Code session in the project directory
   - Step 2: Verify skill loads (ask a basic Astro question, confirm skill-specific behavior)
   - Step 3: Pose the 10-15 noise questions sequentially (each should involve tool use to build context)
   - Step 4: Run `/compact` to force context compaction
   - Step 5: Pose each critical rule verification prompt (R1-R8)
   - Step 6: For each response, check if the expected pattern appears
   - Step 7: Calculate pass rate: N passed / 8 total. Threshold: 80% (at least 7/8 must pass)
   - Step 8: If any rule fails, document which rule and what Claude said instead

5. Add the Go/No-Go Decision template at the end:

   ```markdown
   ## Go/No-Go Decision

   | Category | Status | Threshold | Notes |
   |----------|--------|-----------|-------|
   | TEST-01: Activation | | All positive PASS | Critical |
   | TEST-02: Navigation | | All 11 files PASS | Critical |
   | TEST-03: MCP Boundary | | All boundary tests PASS | Minor reserves OK |
   | TEST-04: Session Resilience | | 80%+ rules retained | Critical |

   **Decision:** [GO / NO-GO / CONDITIONAL]
   **Notes:** [Any caveats, reserves, or conditions]
   ```

Note: This task DESIGNS and DOCUMENTS the test. The actual execution happens in the checkpoint task below, where the user runs the protocol in a real Claude session and fills in the results.
  </action>
  <verify>
- `grep -c "## Test 4" .planning/phases/07-activation-testing/07-VALIDATION.md` returns 1
- `grep -c "## Go/No-Go" .planning/phases/07-activation-testing/07-VALIDATION.md` returns 1
- File contains the 8 critical rule verification prompts (R1-R8)
- File contains the noise conversation design (10-15 questions)
- File contains the testing protocol steps
  </verify>
  <done>
- Test 4 section appended to 07-VALIDATION.md with complete test protocol
- 10-15 noise conversation questions documented
- 8 critical rule verification prompts with expected patterns documented
- Empty results table ready for human to fill in
- Go/No-Go decision template with all 4 test categories
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Session resilience test protocol with noise conversation design, 8 critical rule verification prompts, results template, and go/no-go decision framework. The protocol is ready for execution in a separate Claude Code session.</what-built>
  <how-to-verify>
1. Open `.planning/phases/07-activation-testing/07-VALIDATION.md`
2. Review Test 4 section: Are the noise questions substantive enough to approach compaction? Do they mix Astro and non-Astro topics?
3. Review R1-R8 critical rule prompts: Do they unambiguously test the specific breaking changes and constraints?
4. Review the testing protocol: Are the steps clear enough to follow in a real session?
5. Review Go/No-Go template: Does it capture all 4 test categories with appropriate thresholds?
6. **Execute the protocol:** Start a fresh Claude session, follow the documented steps, fill in the results table
7. After filling results, update the Go/No-Go Decision section

**IMPORTANT:** The session resilience test MUST be run in a separate Claude Code session (not this one) because this session already has the skill loaded and context built up. The test needs a fresh session to properly simulate the activation -> noise -> compaction -> verification cycle.
  </how-to-verify>
  <resume-signal>Type "approved" with the test results (or paste the filled Go/No-Go table), or describe issues found during testing</resume-signal>
</task>

</tasks>

<verification>
- 07-VALIDATION.md contains all 4 test sections (Test 1-4) plus Go/No-Go Decision
- Test 4 has a complete test protocol with noise questions, critical rule prompts, and results template
- Go/No-Go Decision template covers all 4 categories with thresholds from CONTEXT.md
</verification>

<success_criteria>
- TEST-04 protocol designed with 10-15 noise questions and 8 critical rule prompts
- Results table is structured for easy fill-in during manual testing
- Go/No-Go decision framework matches CONTEXT.md criteria: activation + breaking changes = critical, navigation/MCP = minor reserves OK
- Session resilience threshold is 80%+ (at least 7/8 critical rules retained)
- User has executed the protocol and recorded results (or has clear instructions to do so)
</success_criteria>

<output>
After completion, create `.planning/phases/07-activation-testing/07-02-SUMMARY.md`
</output>
