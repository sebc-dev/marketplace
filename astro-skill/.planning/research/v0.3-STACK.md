# Technology Stack: XML Semantic Restructuring

**Project:** Astro-Cloudflare Skill v0.3 -- XML Semantic Containers
**Researched:** 2026-02-04
**Dimension:** Stack (XML/Markdown hybrid patterns for LLM prompt engineering)

## Executive Summary

XML semantic containers are the single most impactful structural improvement available for Claude Code skill reference files. Anthropic's own system prompts use XML tags extensively (`<behavior_instructions>`, `<artifacts_info>`, `<knowledge_cutoff>`), confirming this is not a community workaround but a first-party design pattern. The hybrid approach -- XML for semantic boundaries, Markdown for content inside -- is the correct pattern for this project's 11 reference files (2,915 lines, ~125KB total).

**Core recommendation:** Wrap each functional section in descriptive XML tags using snake_case naming, keep Markdown formatting inside, separate `<rules>` from `<examples>` where applicable, and limit nesting to 2 levels maximum. Expected token overhead: 5-10%. Expected attention improvement: measurable on files above 500 tokens (all 11 files qualify).

---

## Recommended Stack

This is a pure structural reformatting project. There is no runtime technology, no dependencies, no build tools. The "stack" is a set of patterns and conventions.

### Core Pattern: XML/Markdown Hybrid

| Element | Convention | Rationale |
|---------|-----------|-----------|
| Semantic boundaries | XML tags (`<tag_name>`) | Claude trained on XML tags as prompt delimiters (Anthropic docs) |
| Content formatting | Markdown inside XML containers | Headers, lists, tables, code blocks retain readability |
| Tag naming | `snake_case` | Matches Anthropic's internal usage; consistent with multi-word descriptors |
| Nesting depth | Max 2 levels | Beyond 2 levels, attention benefits diminish and token overhead increases |
| Self-closing tags | Never use `<tag/>` | Not documented by Anthropic; Claude may not parse them reliably |

**Confidence: HIGH** -- Based on Anthropic's official documentation and internal system prompt analysis.

### Tag Vocabulary: Recommended Tags for Reference Files

Based on the functional section types present across all 11 reference files:

| Tag | Purpose | When to Use |
|-----|---------|-------------|
| `<quick_reference>` | Numbered rules at file top | Every file (all 11 have Quick Reference sections) |
| `<rules>` | Prescriptive conventions to follow | Sections stating "do this, not that" |
| `<examples>` | Code patterns to imitate | Code blocks demonstrating correct usage |
| `<anti_patterns>` | What to avoid | Every file has Anti-patterns sections |
| `<troubleshooting>` | Symptom/cause/fix tables | Every file has Troubleshooting sections |
| `<decision_matrix>` | Choice tables | Decision tables (rendering mode, hydration, etc.) |
| `<pattern name="...">` | Named architectural pattern | When multiple similar patterns exist (e.g., middleware patterns) |
| `<config>` | Configuration snippets | astro.config, wrangler.toml, tsconfig patterns |
| `<compatibility>` | Feature compatibility matrices | Cross-feature support tables |

**Confidence: MEDIUM** -- Tag names are project-specific recommendations. Anthropic confirms there are no "canonical best" tag names; descriptive names matching content are the guideline.

### What NOT to Tag

| Skip XML For | Reason |
|--------------|--------|
| File title (`# Heading`) | Top-level H1 provides document identity; wrapping it adds no semantic value |
| Single-section files | If file has < 3 distinct sections, Markdown alone suffices |
| Individual list items | Over-tagging; Markdown lists inside a container are sufficient |
| Nested code blocks | Already delimited by triple backticks; XML around them is redundant |
| Tables | Markdown tables are self-contained; XML wrapper needed only for the section containing them |

---

## Measured Benefits and Costs

### Token Overhead

**Estimated overhead per XML tag pair:**

A typical XML tag pair like `<quick_reference>...</quick_reference>` adds:
- Opening tag: 3-5 tokens (`<`, `quick`, `_`, `reference`, `>`)
- Closing tag: 4-6 tokens (`</`, `quick`, `_`, `reference`, `>`)
- Total per container: ~7-11 tokens

**Projected overhead for the full skill:**

| Metric | Value | Source |
|--------|-------|--------|
| Current total lines | 2,915 | Measured |
| Current total bytes | ~125 KB | Measured |
| Estimated current tokens | ~30,000 (at ~4 chars/token) | Approximation |
| Avg sections per file | 8-15 | Measured from H2 counts |
| Total sections across 11 files | ~110 | Counted |
| Tokens added by XML tags | ~110 x 9 = ~990 tokens | Estimate |
| Overhead percentage | ~3.3% | Calculated |

The user's guide document cites 5-10% overhead from Microsoft 2024 studies and community benchmarks. Our estimate of 3.3% is lower because these reference files are content-dense (lots of code blocks and tables that add many tokens relative to the few XML tags wrapping them).

**Confidence: MEDIUM** -- Overhead is estimated, not measured with Anthropic's tokenizer API. The 3-10% range is well-supported across multiple sources.

### Attention Improvement

| Claim | Value | Source | Confidence |
|-------|-------|--------|------------|
| Instruction-following improvement | 10-42% on complex tasks | User's guide doc (citing Microsoft 2024) | MEDIUM |
| Performance variation by format | Up to 40% | Multiple community benchmarks (GPT-3.5 study) | MEDIUM |
| Format-specific improvement for Claude | Meaningful but unquantified | Anthropic docs ("higher-quality outputs") | HIGH (qualitative) |
| Improvement on files > 500 tokens with 3+ sections | Measurable | Consensus across Anthropic docs + community | HIGH |

**Key nuance:** Anthropic does NOT publish specific percentage improvements for XML tags. The 10-42% figure comes from third-party research. What Anthropic does state authoritatively:
1. XML tags improve "clarity," "accuracy," and "flexibility" (official docs)
2. They help Claude "parse prompts more accurately" (official docs)
3. Anthropic uses XML tags extensively in their own system prompts (verified)
4. Claude was "trained with XML tags in the training data" (Anthropic guidance)

**Confidence: HIGH for qualitative benefit, MEDIUM for specific percentages.**

---

## Architecture Decision: Section Identification Strategy

### How to Identify XML Container Boundaries

The current files follow a consistent pattern. The reformatting strategy should exploit this:

**Current structure (all 11 files):**
```
# Title
[Optional subtitle]

## Quick Reference
[Numbered rules]

## [Topical Section 1]
[Content with code, tables]

## [Topical Section 2]
...

## Anti-patterns
[Table: Don't | Do | Impact]

## Troubleshooting
[Table: Symptom | Cause | Fix]
```

**Target structure:**
```xml
# Title
[Optional subtitle]

<quick_reference>
## Rules
[Numbered rules]
</quick_reference>

<section_name>
## [Descriptive Subsection Header]
[Content]
</section_name>

<anti_patterns>
## Common Mistakes
[Table]
</anti_patterns>

<troubleshooting>
## Diagnosis Guide
[Table]
</troubleshooting>
```

**Critical rule from user's guide:** Do NOT duplicate the tag name and the header. If the tag is `<anti_patterns>`, the inner header should be something more specific like "## Common Mistakes" or "## Things That Break", not "## Anti-patterns".

### Files Ranked by XML Benefit

All 11 files have 3+ sections and exceed 500 tokens, meeting the threshold from the decision tree. Priority ranking by section count and complexity:

| File | Lines | H2 Sections | XML Benefit | Notes |
|------|-------|------------|-------------|-------|
| security-advanced.md | 343 | 15 | Highest | Mixed security + MDX/Markdoc domains; semantic boundaries critical |
| build-deploy.md | 262 | 13 | High | CI/CD, debugging, config -- distinct functional areas |
| typescript-testing.md | 282 | ~12 | High | TypeScript + testing are separate concerns in one file |
| data-content.md | 290 | ~11 | High | Content Layer, collections, loaders -- interrelated but distinct |
| styling-performance.md | 296 | ~10 | High | Styling and performance are distinct functional areas |
| routing-navigation.md | 273 | ~10 | High | Routing + navigation + ClientRouter |
| components-islands.md | 265 | ~9 | High | Component patterns + hydration directives |
| seo-i18n.md | 251 | ~9 | Medium-High | SEO and i18n are fairly distinct |
| project-structure.md | 250 | ~8 | Medium | File organization is more hierarchical than sectional |
| cloudflare-platform.md | 242 | ~8 | Medium | Platform bindings -- related but distinct per binding type |
| rendering-modes.md | 161 | 7 | Medium | Smallest file but clear section boundaries |

### Attribute Usage Strategy

Use XML attributes when multiple sibling elements share the same tag type:

```xml
<!-- YES: Multiple patterns of the same kind -->
<pattern name="middleware_security">
## Security Headers
...
</pattern>

<pattern name="middleware_auth">
## Authentication Check
...
</pattern>

<!-- NO: Unique sections don't need attributes -->
<troubleshooting>
## Diagnosis Guide
...
</troubleshooting>
```

**Confidence: HIGH** -- Directly from Anthropic's examples and the user's guide document.

---

## Alternatives Considered

### Alternative 1: Pure Markdown (Status Quo)

| Aspect | Assessment |
|--------|------------|
| Token efficiency | Best (no overhead) |
| Semantic boundaries | Weak (headers only, no explicit open/close) |
| Attention guidance | Relies on positional encoding only |
| Claude parsing | Works but suboptimal for files > 500 tokens |
| **Verdict** | **Reject** -- All files exceed the threshold where XML adds value |

### Alternative 2: Full XML (No Internal Markdown)

| Aspect | Assessment |
|--------|------------|
| Token efficiency | Worst (everything tagged) |
| Semantic boundaries | Overkill (granularity too fine) |
| Human readability | Poor (XML soup) |
| Claude parsing | No demonstrated advantage over hybrid |
| **Verdict** | **Reject** -- Over-tagging is an anti-pattern per Anthropic and user's guide |

### Alternative 3: JSON Structure

| Aspect | Assessment |
|--------|------------|
| Token efficiency | Comparable to XML |
| Claude optimization | Claude optimized for XML, not JSON (per training data) |
| Code block support | Awkward (JSON string escaping for code) |
| Human readability | Poor for documentation content |
| **Verdict** | **Reject** -- JSON is for data transport, not reference documentation |

### Alternative 4: YAML Frontmatter per Section

| Aspect | Assessment |
|--------|------------|
| Token efficiency | Comparable |
| Semantic boundaries | Limited (flat, not hierarchical) |
| Standard support | Not in Anthropic's recommendations |
| **Verdict** | **Reject** -- No evidence Claude treats YAML section markers as attention boundaries |

---

## Tooling

### Validation: No Purpose-Built Tool Exists

There is no existing tool specifically designed to validate XML-in-Markdown hybrid files for Claude prompt engineering. This is unsurprising -- the pattern is relatively niche.

**Pragmatic alternatives:**

| Approach | Feasibility | Notes |
|----------|-------------|-------|
| Manual review | Works for 11 files | Pair each opening and closing tag by eye |
| Simple grep script | Easy to build | `grep -n '<[a-z_]*>' file` vs `grep -n '</[a-z_]*>' file` and compare |
| Custom bash validator | 30 min to write | Check tag balance, nesting depth, naming consistency |
| Existing XML linters | Not recommended | Will reject Markdown content inside tags as invalid XML |

**Recommendation:** Write a simple bash/Python validation script as part of this milestone. It should check:
1. Every opening tag has a matching closing tag
2. No nesting deeper than 2 levels
3. Tag names are snake_case
4. No duplicate header-tag names (tag name !== immediate inner H2 text)
5. No self-closing tags

**Confidence: HIGH** -- The ecosystem was surveyed; no existing tool fits.

### Token Counting: Use Anthropic's API or Third-Party Tools

To measure actual token overhead before/after restructuring:
- **Anthropic Token Count API** (`/v1/messages/count_tokens`) -- authoritative
- **claude-tokenizer.vercel.app** -- quick web-based checks
- **claudetokenizer.com** -- alternative web tool

**Recommendation:** Measure one file before/after as a pilot to validate the 3-10% estimate, then proceed with all 11 files.

---

## Context Engineering Implications

Anthropic's September 2025 blog post on "Effective Context Engineering for AI Agents" introduces the concept of **context rot**: the more tokens in context, the harder it is for Claude to maintain attention on relevant sections. This directly supports our approach:

1. **XML tags create attention anchors** -- When Claude encounters `<troubleshooting>`, it can allocate attention to that section specifically when handling a debugging task, rather than scanning the entire file.

2. **Progressive disclosure is preserved** -- XML containers do not change the loading mechanism. Files are still loaded on-demand by SKILL.md references. XML adds structure within already-loaded content.

3. **Context window is a public good** -- Anthropic's skill authoring guidance states this explicitly. Every token in a skill reference shares the context window with the user's task. XML overhead must earn its keep through improved attention precision. At 3-10% overhead for measurable parsing improvement, the trade is worthwhile.

4. **No content changes needed** -- This restructuring is purely additive (XML tags around existing content). No content is modified, removed, or rewritten. This means zero regression risk on the validated v0.2 content.

---

## Implementation Rules

### The Transformation Protocol

For each file, the transformation follows this exact sequence:

1. **Identify section boundaries** -- Map every `## ` header and its content span
2. **Group related sections** -- Some adjacent H2 sections belong in one XML container (e.g., multiple middleware patterns under one `<middleware>` or distinct `<pattern name="...">` containers)
3. **Choose tag name** -- Descriptive, snake_case, different from the inner H2 header text
4. **Wrap sections** -- Add opening tag before first line, closing tag after last line of section
5. **Verify tag balance** -- Every opener has a closer
6. **Verify no content changes** -- Diff should show ONLY added XML tag lines

### Tag Naming Convention (Definitive)

| Rule | Example | Counter-Example |
|------|---------|-----------------|
| snake_case for multi-word | `<quick_reference>` | `<quickReference>`, `<QuickReference>` |
| Single word when natural | `<rules>`, `<examples>` | `<rules_section>` (unnecessary suffix) |
| Describes content, not format | `<server_islands>` | `<section_3>` |
| Different from inner H2 | `<anti_patterns>` wrapping "## Common Mistakes" | `<anti_patterns>` wrapping "## Anti-patterns" |
| No attributes unless disambiguating | `<troubleshooting>` | `<section type="troubleshooting">` |
| Attributes for repeated types | `<pattern name="auth_middleware">` | `<auth_middleware_pattern>` |

### Nesting Rules

```xml
<!-- Level 1: OK (primary container) -->
<security>
## Headers
...

<!-- Level 2: OK (sub-container for distinct concern) -->
<csp_config>
### Content Security Policy
...
</csp_config>

</security>

<!-- Level 3: NEVER -->
<security>
  <csp_config>
    <directives>   <!-- TOO DEEP -->
    ...
    </directives>
  </csp_config>
</security>
```

In practice, most reference file sections need only 1 level of XML nesting. Level 2 should be reserved for the `security-advanced.md` file where security and MDX/Markdoc are genuinely separate domains within one file.

---

## Sources

### HIGH Confidence (Official Anthropic)
- [Use XML tags to structure your prompts](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags) -- Anthropic official documentation
- [Skill authoring best practices](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/best-practices) -- Anthropic official skill guidance
- [Agent Skills Overview](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview) -- Progressive disclosure mechanism
- [Effective context engineering for AI agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents) -- Context rot, attention boundaries
- [Prompt engineering overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview) -- XML as recommended technique
- [Claude 4.x best practices](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-4-best-practices) -- Literal instruction following

### MEDIUM Confidence (Verified Analysis)
- [Claude Skills Deep Dive](https://leehanchung.github.io/blogs/2025/10/26/claude-skills-deep-dive/) -- Loading mechanism analysis (verified against official docs)
- [Inside Claude Code Skills](https://mikhail.io/2025/10/claude-code-skills/) -- Skill routing via XML in tool descriptions
- [Markdown vs XML in LLM Prompts](https://www.robertodiasduarte.com.br/en/markdown-vs-xml-em-prompts-para-llms-uma-analise-comparativa/) -- Token overhead comparison (~15% difference)
- [Claude Prompt Engineering Guide](https://github.com/ThamJiaHe/claude-prompt-engineering-guide) -- Community guide (170+ sources, updated Jan 2026)

### LOW Confidence (Community/Unverified)
- [Stop Writing Blob-Prompts](https://pub.towardsai.net/stop-writing-blob-prompts-anthropics-xml-tags-turn-claude-into-a-contract-machine-aa45ccc4232c) -- "XML turns Claude into a contract machine" (good framing but unverified claims)
- [Skyvern HTML vs JSON study](https://blog.skyvern.com/how-we-cut-token-count-by-11-and-boosted-success-rate-by-3-9-by-using-html-instead-of-json-in-our-llm-calls/) -- 11% token reduction with HTML vs JSON (different context but relevant data point)
- Microsoft 2024 study on 10-42% improvement -- Cited in user's guide but original paper not located; treat specific percentages as approximate

---

## Gaps to Address

1. **Exact token measurement** -- Overhead estimate is approximate. Measure with Anthropic's tokenizer API on pilot file before proceeding.
2. **Validation tooling** -- No existing tool; build a simple validator as part of implementation.
3. **Attention measurement** -- No way to directly measure Claude's internal attention patterns. Quality validation must be behavioral (does Claude follow rules better with XML containers?).
4. **Claude 4.x literal interpretation** -- Claude 4.x takes instructions literally. Verify that XML containers do not cause Claude to treat tag names as additional instructions (unlikely but untested for skill references specifically).
